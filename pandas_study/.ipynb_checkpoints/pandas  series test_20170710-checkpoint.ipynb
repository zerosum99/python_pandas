{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 판다스 1 차원 Series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T abs add add_prefix add_suffix align all any append apply argmax argmin argsort as_blocks as_matrix asfreq asobject asof astype at at_time autocorr axes base between between_time bfill blocks bool cat clip clip_lower clip_upper combine combine_first compound compress consolidate convert_objects copy corr count cov cummax cummin cumprod cumsum data describe diff div divide dot drop drop_duplicates dropna dt dtype dtypes duplicated empty eq equals ewm expanding factorize ffill fillna filter first first_valid_index flags floordiv from_array from_csv ftype ftypes ge get get_dtype_counts get_ftype_counts get_value get_values groupby gt hasnans head hist iat idxmax idxmin iget iget_value iloc imag index interpolate irow is_copy is_time_series is_unique isin isnull item items itemsize iteritems iterkv ix keys kurt kurtosis last last_valid_index le loc lt mad map mask max mean median memory_usage min mod mode mul multiply name nbytes ndim ne nlargest nonzero notnull nsmallest nunique order pct_change pipe plot pop pow prod product ptp put quantile radd rank ravel rdiv real reindex reindex_axis reindex_like rename rename_axis reorder_levels repeat replace resample reset_index reshape rfloordiv rmod rmul rolling round rpow rsub rtruediv sample searchsorted select sem set_axis set_value shape shift size skew slice_shift sort sort_index sort_values sortlevel squeeze std str strides sub subtract sum swapaxes swaplevel tail take to_clipboard to_csv to_dense to_dict to_frame to_hdf to_json to_msgpack to_period to_pickle to_sparse to_sql to_string to_timestamp to_xarray tolist transpose truediv truncate tshift tz_convert tz_localize unique unstack update valid value_counts values var view where xs "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i in dir(pd.Series) :\n",
    "    if not i.startswith(\"_\") :\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series 클래스에 추가된 메소드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolate to_dict append head rsub rank reset_index convert_objects dtypes set_value ffill rfloordiv swaplevel as_blocks to_dense combine asfreq rename idxmin bool last_valid_index ewm hist get_value first_valid_index from_array to_sql quantile is_time_series is_copy irow tshift lt multiply nsmallest get ix cummin to_pickle rename_axis add_prefix last empty set_axis sub mod duplicated as_matrix plot combine_first keys value_counts ftypes slice_shift unique truediv to_csv clip_upper to_sparse abs mad get_dtype_counts ge iterkv shift sample drop memory_usage consolidate is_unique values to_msgpack describe reorder_levels xs pct_change nunique rpow le to_hdf product tz_convert align cummax idxmax to_timestamp bfill pop axes mask rdiv mode truncate name fillna expanding median dropna between_time iget_value gt asof asobject hasnans between dt to_json at_time pipe unstack pow iat add_suffix to_string get_ftype_counts sem iget tz_localize drop_duplicates rtruediv sort_values sort_index equals replace apply divide subtract order rmul skew reindex_axis index compound loc to_clipboard resample rolling at update mul to_xarray autocorr rmod select valid div floordiv tail ftype cat count isnull sortlevel first to_frame get_values notnull iloc str add iteritems kurt diff items nlargest clip_lower filter from_csv radd reindex corr reindex_like isin ne cov eq blocks map kurtosis factorize where groupby to_period "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nd = set(dir(np.ndarray))\n",
    "pd = set(dir(pd.Series))\n",
    "\n",
    "ser = pd - nd\n",
    "\n",
    "for i in ser :\n",
    "    if not i.startswith(\"_\") :\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy와 동일한 메소드\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strides max astype ravel reshape flags itemsize swapaxes take mean ptp argmin cumsum cumprod argsort T tolist argmax put nonzero searchsorted repeat round copy transpose imag dtype dot std base compress shape sort clip sum any prod item squeeze var ndim nbytes size view data all min real "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nd = set(dir(np.ndarray))\n",
    "pd = set(dir(pd.Series))\n",
    "\n",
    "ser = pd & nd\n",
    "\n",
    "for i in ser :\n",
    "    if not i.startswith(\"_\") :\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차원 생성 \n",
    "\n",
    "    data : 배열 형, dict 또는 스칼라 값, 시리즈에 저장된 데이터 포함\n",
    "    색인 : 배열과 유사하거나 색인 (1d)\n",
    "            값은 해시 가능해야하며 데이터와 길이가 같아야합니다. 고유하지 않은 색인 값이 허용됩니다. 제공되지 않을 경우\n",
    "            RangeIndex (len (data))를 기본값으로 사용합니다. dict 및 인덱스 시퀀스가 모두 사용되면 인덱스는 dict에있는\n",
    "            키를 재정의합니다.\n",
    "    dtype : numpy.dtype 또는 없음  None이면 dtype이 유추됩니다.\n",
    "    copy : 부울, 기본값 False     입력 데이터 복사\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64\n",
      "b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
      "RangeIndex(start=0, stop=4, step=1)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "obj = pd.Series([1,2,3,4])\n",
    "print(obj)\n",
    "\n",
    "print(obj.data.tobytes())\n",
    "print(obj.index)\n",
    "print(obj.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dict 타입으로 지정해서 자동 인덱스 처리 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "Name: something, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'a':1,'b':2,'c':3}\n",
    "s3 = pd.Series(d,name='something')\n",
    "\n",
    "print(s3.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: test, dtype: int64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "index = ['a','b','c','d']\n",
    "obj1 = pd.Series([1,2,3,4],index=index,name=\"test\") \n",
    "\n",
    "print(obj1)\n",
    "print(obj1['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 속성  : 넘파이와 동일한 속성\n",
    "\n",
    "\n",
    "    \n",
    "     base\t    return the base object if the memory of the underlying data is blocks Internal property,\n",
    "                property synonym for as_blocks()\n",
    "     data\t     return the data pointer of the underlying data\n",
    "    dtype\t    return the dtype object of the underlying data\n",
    "    dtypes\t    return the dtype object of the underlying data\n",
    "    imag\t\n",
    "    itemsize    return the size of the dtype of the item of the underlying data\n",
    "    nbytes\t    return the number of bytes in the underlying data\n",
    "    ndim\t    return the number of dimensions of the underlying data,\n",
    "    real\t\n",
    "       T\t    return the transpose, which is by definition self\n",
    "    shape\t     return a tuple of the shape of the underlying data\n",
    "    size\t    return the number of elements in the underlying data\n",
    "    strides\t    return the strides of the underlying data\n",
    "    values\t    Return Series as ndarray or ndarray-like\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "32\n",
      "1\n",
      "(4,)\n",
      "(8,)\n",
      "[1 2 3 4]\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: obj, dtype: int64\n",
      "{'int64': 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: obj, dtype: int64}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "obj = pd.Series([1,2,3,4],name=\"obj\")\n",
    "\n",
    "print(obj.itemsize)\n",
    "print(obj.nbytes)\n",
    "print(obj.ndim)\n",
    "print(obj.shape)\n",
    "print(obj.strides)\n",
    "print(obj.values)\n",
    "print(obj.T)\n",
    "print(obj.blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  blocks 속성에 대한 내부 정보\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'int64': 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: test, dtype: int64}\n",
      "Int64Index([0, 1, 2, 3], dtype='int64')\n",
      "[1 2 3 4]\n",
      "test\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "obj1 = pd.Series([1,2,3,4],name=\"test\")\n",
    " \n",
    "print(obj1.blocks)\n",
    "print(obj1.blocks['int64'].index)\n",
    "print(obj1.blocks['int64'].values)\n",
    "print(obj1.blocks['int64'].name)\n",
    "print(obj1.blocks['int64'].dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 속성  : pandas 추가 속성 \n",
    "\n",
    "    asobject\treturn object Series which contains boxed values\n",
    "    at\t        Fast label-based scalar accessor\n",
    "    axes\t    Return a list of the row axis labels\n",
    "    empty\t\n",
    "    flags\t\n",
    "    ftype\t    return if the data is sparse|dense\n",
    "    ftypes\t    return if the data is sparse|dense\n",
    "    hasnans\t\n",
    "    iat  \t    Fast integer location scalar accessor.\n",
    "    iloc\t    Purely integer-location based indexing for selection by position.\n",
    "    is_copy\t\n",
    "    is_monotonic\t          Return boolean if values in the object are\n",
    "    is_monotonic_decreasing\t  Return boolean if values in the object are\n",
    "    is_monotonic_increasing\t  Return boolean if values in the object are\n",
    "    is_unique\t              Return boolean if values in the object are unique\n",
    "   \n",
    "    ix\t        A primarily label-location based indexer, with integer position fallback.\n",
    "    loc\t        Purely label-location based indexer for selection by label.\n",
    "    name\t\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주요 Series 인스턴스의 값을 접근하기 위해 at은 원소의 값, loc는 슬라이싱 처리를 포함해서 검색, ix는 값을 검색 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "Name: obj, dtype: int64 Series([], Name: obj, dtype: int64)\n",
      "<class 'numpy.int64'> True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "obj1 = pd.Series([1,2,3,4],name=\"test\") \n",
    "\n",
    "obj1.index = ['a','b','c','d']\n",
    "print(obj1.at['a'])\n",
    "print(obj1.iat[0])\n",
    "\n",
    "print(obj.iloc[0:3],obj.loc['a':'c'])\n",
    "\n",
    "print(type(obj1.ix['a']),obj1.ix['a'] == 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인덱스 및 Series 이름 부여\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['a', 'b', 'c'], dtype='object')\n",
      "[4 5 6]\n",
      "Series Data\n",
      "int64\n",
      "1\n",
      "(3,)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s3 = pd.Series([4, 5, 6], index=['a','b','c'], name=\"Series Data\")\n",
    "\n",
    "print(s3.index)\n",
    "print(s3.values)\n",
    "print(s3.name)\n",
    "print(s3.dtype)\n",
    "print(s3.ndim)\n",
    "print(s3.shape)\n",
    "print(s3.strides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터는 기본적으로 view 체계로 구성\n",
    "\n",
    "    기본적으로 대량 처리 계산을 위해서 기본으로 view를 제공한다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    999\n",
      "1      2\n",
      "2      3\n",
      "3      4\n",
      "dtype: int64\n",
      "0    999\n",
      "1      2\n",
      "2      3\n",
      "3      4\n",
      "dtype: int64\n",
      "[999   2   3   4]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "obj1 = pd.Series([1,2,3,4])\n",
    "obj2 = obj1[:]\n",
    "\n",
    "obj2[0] = 999\n",
    "\n",
    "print(obj1)\n",
    "print(obj2)\n",
    "print(obj2.base)\n",
    "\n",
    "print(np.may_share_memory(obj1,obj2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  두 개를 연결하기 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "0    4\n",
      "1    5\n",
      "2    6\n",
      "dtype: int64\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s1 = pd.Series([1, 2, 3])\n",
    "s2 = pd.Series([4, 5, 6])\n",
    "s3 = pd.Series([4, 5, 6], index=[3,4,5])\n",
    "s = s1.append(s2)\n",
    "print(s)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "int64:dense\n",
      "[Index(['a', 'b', 'c'], dtype='object')]\n",
      "False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s3 = pd.Series([4, 5, 6], index=['a','b','c'], name=\"Series Data\")\n",
    "\n",
    "print(s3.size)\n",
    "print(s3.ftypes)\n",
    "print(s3.axes)\n",
    "print(s3.empty)\n",
    "print(s3.base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'int64': a    4\n",
      "b    5\n",
      "c    6\n",
      "Name: Series Data, dtype: int64}\n",
      "a    4\n",
      "b    5\n",
      "c    6\n",
      "Name: Series Data, dtype: int64\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "s3 = pd.Series([4, 5, 6], index=['a','b','c'], name=\"Series Data\")\n",
    "\n",
    "print(s3.blocks)\n",
    "print(s3.T)\n",
    "\n",
    "print(np.dot(s3,s3.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "a    4\n",
      "b    5\n",
      "dtype: int64\n",
      "<pandas.core.indexing._LocIndexer object at 0x0000000006555208>\n",
      "a    4\n",
      "b    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "s1 = pd.Series([1, 2, 3])\n",
    "print(s1[0])\n",
    "\n",
    "s3 = pd.Series([4, 5, 6], index=['a','b','c'])\n",
    "print(s3[['a','b']])\n",
    "\n",
    "print(s3.loc)\n",
    "print(s3.loc[['a','b']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _LocIndexer in module pandas.core.indexing object:\n",
      "\n",
      "class _LocIndexer(_LocationIndexer)\n",
      " |  Purely label-location based indexer for selection by label.\n",
      " |  \n",
      " |  ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |  boolean array.\n",
      " |  \n",
      " |  Allowed inputs are:\n",
      " |  \n",
      " |  - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |    interpreted as a *label* of the index, and **never** as an\n",
      " |    integer position along the index).\n",
      " |  - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |  - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n",
      " |    to usual python slices, **both** the start and the stop are included!).\n",
      " |  - A boolean array.\n",
      " |  - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |    or Panel) and that returns valid output for indexing (one of the above)\n",
      " |  \n",
      " |  ``.loc`` will raise a ``KeyError`` when the items are not found.\n",
      " |  \n",
      " |  See more at :ref:`Selection by Label <indexing.label>`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      _LocIndexer\n",
      " |      _LocationIndexer\n",
      " |      _NDFrameIndexer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from _LocationIndexer:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  __call__(self, axis=None)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __init__(self, obj, name)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  axis = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(s3.loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "3    2\n",
      "1    3\n",
      "4    4\n",
      "2    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "obj = pd.Series([1,3,5,2,4])\n",
    "\n",
    "obj.sort_values(inplace=True)\n",
    "print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    3\n",
      "2    5\n",
      "3    2\n",
      "4    4\n",
      "dtype: int64\n",
      "3    2\n",
      "2    5\n",
      "0    1\n",
      "1    3\n",
      "4    4\n",
      "dtype: int64\n",
      "0    2\n",
      "1    5\n",
      "2    1\n",
      "3    3\n",
      "4    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "obj = pd.Series([1,3,5,2,4])\n",
    "\n",
    "print(obj)\n",
    "obj1 = obj.reindex([3,2,0,1,4])\n",
    "print(obj1)\n",
    "\n",
    "obj1.index = [0,1,2,3,4]\n",
    "print(obj1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method reindex in module pandas.core.series:\n",
      "\n",
      "reindex(index=None, **kwargs) method of pandas.core.series.Series instance\n",
      "    Conform Series to new index with optional filling logic, placing\n",
      "    NA/NaN in locations having no value in the previous index. A new object\n",
      "    is produced unless the new index is equivalent to the current one and\n",
      "    copy=False\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    index : array-like, optional (can be specified in order, or as\n",
      "        keywords)\n",
      "        New labels / index to conform to. Preferably an Index object to\n",
      "        avoid duplicating data\n",
      "    method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      "        method to use for filling holes in reindexed DataFrame.\n",
      "        Please note: this is only  applicable to DataFrames/Series with a\n",
      "        monotonically increasing/decreasing index.\n",
      "    \n",
      "        * default: don't fill gaps\n",
      "        * pad / ffill: propagate last valid observation forward to next\n",
      "          valid\n",
      "        * backfill / bfill: use next valid observation to fill gap\n",
      "        * nearest: use nearest valid observations to fill gap\n",
      "    \n",
      "    copy : boolean, default True\n",
      "        Return a new object, even if the passed indexes are the same\n",
      "    level : int or name\n",
      "        Broadcast across a level, matching Index values on the\n",
      "        passed MultiIndex level\n",
      "    fill_value : scalar, default np.NaN\n",
      "        Value to use for missing values. Defaults to NaN, but can be any\n",
      "        \"compatible\" value\n",
      "    limit : int, default None\n",
      "        Maximum number of consecutive elements to forward or backward fill\n",
      "    tolerance : optional\n",
      "        Maximum distance between original and new labels for inexact\n",
      "        matches. The values of the index at the matching locations most\n",
      "        satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      "    \n",
      "        .. versionadded:: 0.17.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    Create a dataframe with some fictional data.\n",
      "    \n",
      "    >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      "    >>> df = pd.DataFrame({\n",
      "    ...      'http_status': [200,200,404,404,301],\n",
      "    ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      "    ...       index=index)\n",
      "    >>> df\n",
      "                http_status  response_time\n",
      "    Firefox            200           0.04\n",
      "    Chrome             200           0.02\n",
      "    Safari             404           0.07\n",
      "    IE10               404           0.08\n",
      "    Konqueror          301           1.00\n",
      "    \n",
      "    Create a new index and reindex the dataframe. By default\n",
      "    values in the new index that do not have corresponding\n",
      "    records in the dataframe are assigned ``NaN``.\n",
      "    \n",
      "    >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      "    ...             'Chrome']\n",
      "    >>> df.reindex(new_index)\n",
      "                   http_status  response_time\n",
      "    Safari                 404           0.07\n",
      "    Iceweasel              NaN            NaN\n",
      "    Comodo Dragon          NaN            NaN\n",
      "    IE10                   404           0.08\n",
      "    Chrome                 200           0.02\n",
      "    \n",
      "    We can fill in the missing values by passing a value to\n",
      "    the keyword ``fill_value``. Because the index is not monotonically\n",
      "    increasing or decreasing, we cannot use arguments to the keyword\n",
      "    ``method`` to fill the ``NaN`` values.\n",
      "    \n",
      "    >>> df.reindex(new_index, fill_value=0)\n",
      "                   http_status  response_time\n",
      "    Safari                 404           0.07\n",
      "    Iceweasel                0           0.00\n",
      "    Comodo Dragon            0           0.00\n",
      "    IE10                   404           0.08\n",
      "    Chrome                 200           0.02\n",
      "    \n",
      "    >>> df.reindex(new_index, fill_value='missing')\n",
      "                  http_status response_time\n",
      "    Safari                404          0.07\n",
      "    Iceweasel         missing       missing\n",
      "    Comodo Dragon     missing       missing\n",
      "    IE10                  404          0.08\n",
      "    Chrome                200          0.02\n",
      "    \n",
      "    To further illustrate the filling functionality in\n",
      "    ``reindex``, we will create a dataframe with a\n",
      "    monotonically increasing index (for example, a sequence\n",
      "    of dates).\n",
      "    \n",
      "    >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      "    >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      "    ...                    index=date_index)\n",
      "    >>> df2\n",
      "                prices\n",
      "    2010-01-01     100\n",
      "    2010-01-02     101\n",
      "    2010-01-03     NaN\n",
      "    2010-01-04     100\n",
      "    2010-01-05      89\n",
      "    2010-01-06      88\n",
      "    \n",
      "    Suppose we decide to expand the dataframe to cover a wider\n",
      "    date range.\n",
      "    \n",
      "    >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      "    >>> df2.reindex(date_index2)\n",
      "                prices\n",
      "    2009-12-29     NaN\n",
      "    2009-12-30     NaN\n",
      "    2009-12-31     NaN\n",
      "    2010-01-01     100\n",
      "    2010-01-02     101\n",
      "    2010-01-03     NaN\n",
      "    2010-01-04     100\n",
      "    2010-01-05      89\n",
      "    2010-01-06      88\n",
      "    2010-01-07     NaN\n",
      "    \n",
      "    The index entries that did not have a value in the original data frame\n",
      "    (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      "    If desired, we can fill in the missing values using one of several\n",
      "    options.\n",
      "    \n",
      "    For example, to backpropagate the last valid value to fill the ``NaN``\n",
      "    values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      "    \n",
      "    >>> df2.reindex(date_index2, method='bfill')\n",
      "                prices\n",
      "    2009-12-29     100\n",
      "    2009-12-30     100\n",
      "    2009-12-31     100\n",
      "    2010-01-01     100\n",
      "    2010-01-02     101\n",
      "    2010-01-03     NaN\n",
      "    2010-01-04     100\n",
      "    2010-01-05      89\n",
      "    2010-01-06      88\n",
      "    2010-01-07     NaN\n",
      "    \n",
      "    Please note that the ``NaN`` value present in the original dataframe\n",
      "    (at index value 2010-01-03) will not be filled by any of the\n",
      "    value propagation schemes. This is because filling while reindexing\n",
      "    does not look at dataframe values, but only compares the original and\n",
      "    desired indexes. If you do want to fill in the ``NaN`` values present\n",
      "    in the original dataframe, use the ``fillna()`` method.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    reindexed : Series\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(obj.reindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    3\n",
      "2    5\n",
      "3    2\n",
      "4    4\n",
      "0    1\n",
      "1    3\n",
      "2    5\n",
      "3    2\n",
      "4    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "obj = pd.Series([1,3,5,2,4])\n",
    "\n",
    "obj1 = pd.Series([1,3,5,2,4])\n",
    "\n",
    "obj2 = obj.append(obj1)\n",
    "print(obj2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method append in module pandas.core.series:\n",
      "\n",
      "append(to_append, verify_integrity=False) method of pandas.core.series.Series instance\n",
      "    Concatenate two or more Series.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    to_append : Series or list/tuple of Series\n",
      "    verify_integrity : boolean, default False\n",
      "        If True, raise Exception on creating index with duplicates\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    appended : Series\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> s1 = pd.Series([1, 2, 3])\n",
      "    >>> s2 = pd.Series([4, 5, 6])\n",
      "    >>> s3 = pd.Series([4, 5, 6], index=[3,4,5])\n",
      "    >>> s1.append(s2)\n",
      "    0    1\n",
      "    1    2\n",
      "    2    3\n",
      "    0    4\n",
      "    1    5\n",
      "    2    6\n",
      "    dtype: int64\n",
      "    \n",
      "    >>> s1.append(s3)\n",
      "    0    1\n",
      "    1    2\n",
      "    2    3\n",
      "    3    4\n",
      "    4    5\n",
      "    5    6\n",
      "    dtype: int64\n",
      "    \n",
      "    With `verify_integrity` set to True:\n",
      "    \n",
      "    >>> s1.append(s2, verify_integrity=True)\n",
      "    ValueError: Indexes have overlapping values: [0, 1, 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(obj.append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Hello world\n",
      "1    Python pandas\n",
      "dtype: object\n",
      "0      [Hello, world]\n",
      "1    [Python, pandas]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "obj = pd.Series(['Hello world', 'Python pandas'])\n",
    "print(obj)\n",
    "print(obj.str.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    NaN\n",
      "b    2.0\n",
      "c    3.0\n",
      "dtype: float64\n",
      "A     True\n",
      "b    False\n",
      "c    False\n",
      "dtype: bool\n",
      "A    False\n",
      "b     True\n",
      "c     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d,index=['A','b','c'])\n",
    "print(obj)\n",
    "\n",
    "print(pd.isnull(obj))\n",
    "print(pd.notnull(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "dtype: int64\n",
      "alpha\n",
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d)\n",
    "print(obj)\n",
    "obj.index.name = 'alpha'\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Index in module pandas.indexes.base object:\n",
      "\n",
      "class Index(pandas.core.base.IndexOpsMixin, pandas.core.strings.StringAccessorMixin, pandas.core.base.PandasObject)\n",
      " |  Immutable ndarray implementing an ordered, sliceable set. The basic object\n",
      " |  storing axis labels for all pandas objects\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : array-like (1-dimensional)\n",
      " |  dtype : NumPy dtype (default: object)\n",
      " |  copy : bool\n",
      " |      Make a copy of input ndarray\n",
      " |  name : object\n",
      " |      Name to be stored in the index\n",
      " |  tupleize_cols : bool (default: True)\n",
      " |      When True, attempt to create a MultiIndex if possible\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  An Index instance can **only** contain hashable objects\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Index\n",
      " |      pandas.core.base.IndexOpsMixin\n",
      " |      pandas.core.strings.StringAccessorMixin\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __abs__(self, other=None)\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  __and__(self, other)\n",
      " |  \n",
      " |  __array__(self, dtype=None)\n",
      " |      the array interface, return my values\n",
      " |  \n",
      " |  __array_wrap__(self, result, context=None)\n",
      " |      Gets called after a ufunc\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |  \n",
      " |  __copy__ = copy(self, name=None, deep=False, dtype=None, **kwargs)\n",
      " |  \n",
      " |  __deepcopy__(self, memo=None)\n",
      " |  \n",
      " |  __eq__ = _evaluate_compare(self, other)\n",
      " |  \n",
      " |  __floordiv__(self, other=None)\n",
      " |  \n",
      " |  __ge__ = _evaluate_compare(self, other)\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |      Override numpy.ndarray's __getitem__ method to work as desired.\n",
      " |      \n",
      " |      This function adds lists and Series as valid boolean indexers\n",
      " |      (ndarrays only supports ndarray with dtype=bool).\n",
      " |      \n",
      " |      If resulting ndim != 1, plain ndarray is returned instead of\n",
      " |      corresponding `Index` subclass.\n",
      " |  \n",
      " |  __gt__ = _evaluate_compare(self, other)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __iadd__ = __add__(self, other)\n",
      " |  \n",
      " |  __inv__(self, other=None)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __le__ = _evaluate_compare(self, other)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      return the length of the Index\n",
      " |  \n",
      " |  __lt__ = _evaluate_compare(self, other)\n",
      " |  \n",
      " |  __mul__(self, other=None)\n",
      " |  \n",
      " |  __ne__ = _evaluate_compare(self, other)\n",
      " |  \n",
      " |  __neg__(self, other=None)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __or__(self, other)\n",
      " |  \n",
      " |  __pos__(self, other=None)\n",
      " |  \n",
      " |  __pow__(self, other=None)\n",
      " |  \n",
      " |  __radd__(self, other)\n",
      " |  \n",
      " |  __reduce__(self)\n",
      " |      helper for pickle\n",
      " |  \n",
      " |  __rfloordiv__ = __floordiv__(self, other=None)\n",
      " |  \n",
      " |  __rmul__ = __mul__(self, other=None)\n",
      " |  \n",
      " |  __rpow__ = __pow__(self, other=None)\n",
      " |  \n",
      " |  __rtruediv__ = __truediv__(self, other=None)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |      Necessary for making this object picklable\n",
      " |  \n",
      " |  __sub__(self, other)\n",
      " |  \n",
      " |  __truediv__(self, other=None)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for this object.\n",
      " |      \n",
      " |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  __xor__(self, other)\n",
      " |  \n",
      " |  all(self, *args, **kwargs)\n",
      " |      Return whether all elements are True\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      All arguments to numpy.all are accepted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      all : bool or array_like (if axis is specified)\n",
      " |          A single element array_like may be converted to bool.\n",
      " |  \n",
      " |  any(self, *args, **kwargs)\n",
      " |      Return whether any element is True\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      All arguments to numpy.any are accepted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      any : bool or array_like (if axis is specified)\n",
      " |          A single element array_like may be converted to bool.\n",
      " |  \n",
      " |  append(self, other)\n",
      " |      Append a collection of Index options together\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Index or list/tuple of indices\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      appended : Index\n",
      " |  \n",
      " |  argsort(self, *args, **kwargs)\n",
      " |      Returns the indices that would sort the index and its\n",
      " |      underlying data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      argsorted : numpy array\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.argsort\n",
      " |  \n",
      " |  asof(self, label)\n",
      " |      For a sorted index, return the most recent label up to and including\n",
      " |      the passed label. Return NaN if not found.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      get_loc : asof is a thin wrapper around get_loc with method='pad'\n",
      " |  \n",
      " |  asof_locs(self, where, mask)\n",
      " |      where : array of timestamps\n",
      " |      mask : array of booleans where data is not NA\n",
      " |  \n",
      " |  astype(self, dtype)\n",
      " |  \n",
      " |  copy(self, name=None, deep=False, dtype=None, **kwargs)\n",
      " |      Make a copy of this object.  Name and dtype sets those attributes on\n",
      " |      the new object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string, optional\n",
      " |      deep : boolean, default False\n",
      " |      dtype : numpy dtype or pandas type\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      In most cases, there should be no functional difference from using\n",
      " |      ``deep``, but if ``deep`` is passed it will attempt to deepcopy.\n",
      " |  \n",
      " |  delete(self, loc)\n",
      " |      Make new Index with passed location(-s) deleted\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      new_index : Index\n",
      " |  \n",
      " |  diff = wrapper(*args, **kwargs)\n",
      " |  \n",
      " |  difference(self, other)\n",
      " |      Return a new Index with elements from the index that are not in\n",
      " |      `other`.\n",
      " |      \n",
      " |      This is the sorted set difference of two Index objects.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Index or array-like\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      difference : Index\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> idx1 = pd.Index([1, 2, 3, 4])\n",
      " |      >>> idx2 = pd.Index([3, 4, 5, 6])\n",
      " |      >>> idx1.difference(idx2)\n",
      " |      Int64Index([1, 2], dtype='int64')\n",
      " |  \n",
      " |  drop(self, labels, errors='raise')\n",
      " |      Make new Index with passed list of labels deleted\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : array-like\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and existing labels are dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dropped : Index\n",
      " |  \n",
      " |  drop_duplicates(self, keep='first')\n",
      " |      Return Index with duplicate values removed\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      " |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      " |          - False : Drop all duplicates.\n",
      " |      take_last : deprecated\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      deduplicated : Index\n",
      " |  \n",
      " |  duplicated(self, keep='first')\n",
      " |      Return boolean np.array denoting duplicate values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - ``first`` : Mark duplicates as ``True`` except for the first\n",
      " |            occurrence.\n",
      " |          - ``last`` : Mark duplicates as ``True`` except for the last\n",
      " |            occurrence.\n",
      " |          - False : Mark all duplicates as ``True``.\n",
      " |      take_last : deprecated\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      duplicated : np.array\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Determines if two Index objects contain the same elements.\n",
      " |  \n",
      " |  fillna(self, value=None, downcast=None)\n",
      " |      Fill NA/NaN values with the specified value\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar\n",
      " |          Scalar value to use to fill holes (e.g. 0).\n",
      " |          This value cannot be a list-likes.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : %(klass)s\n",
      " |  \n",
      " |  format(self, name=False, formatter=None, **kwargs)\n",
      " |      Render a string representation of the Index\n",
      " |  \n",
      " |  get_duplicates(self)\n",
      " |  \n",
      " |  get_indexer(self, target, method=None, limit=None, tolerance=None)\n",
      " |      Compute indexer and mask for new index given the current index. The\n",
      " |      indexer should be then used as an input to ndarray.take to align the\n",
      " |      current data to the new index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      target : Index\n",
      " |      method : {None, 'pad'/'ffill', 'backfill'/'bfill', 'nearest'}, optional\n",
      " |          * default: exact matches only.\n",
      " |          * pad / ffill: find the PREVIOUS index value if no exact match.\n",
      " |          * backfill / bfill: use NEXT index value if no exact match\n",
      " |          * nearest: use the NEAREST index value if no exact match. Tied\n",
      " |            distances are broken by preferring the larger index value.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive labels in ``target`` to match for\n",
      " |          inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> indexer = index.get_indexer(new_index)\n",
      " |      >>> new_values = cur_values.take(indexer)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indexer : ndarray of int\n",
      " |          Integers from 0 to n - 1 indicating that the index at these\n",
      " |          positions matches the corresponding target values. Missing values\n",
      " |          in the target are marked by -1.\n",
      " |  \n",
      " |  get_indexer_for(self, target, **kwargs)\n",
      " |      guaranteed return of an indexer even when non-unique\n",
      " |  \n",
      " |  get_indexer_non_unique(self, target)\n",
      " |      return an indexer suitable for taking from a non unique index\n",
      " |      return the labels in the same order as the target, and\n",
      " |      return a missing indexer into the target (missing are marked as -1\n",
      " |      in the indexer); target must be an iterable\n",
      " |  \n",
      " |  get_level_values(self, level)\n",
      " |      Return vector of label values for requested level, equal to the length\n",
      " |      of the index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : ndarray\n",
      " |  \n",
      " |  get_loc(self, key, method=None, tolerance=None)\n",
      " |      Get integer location for requested label\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : label\n",
      " |      method : {None, 'pad'/'ffill', 'backfill'/'bfill', 'nearest'}, optional\n",
      " |          * default: exact matches only.\n",
      " |          * pad / ffill: find the PREVIOUS index value if no exact match.\n",
      " |          * backfill / bfill: use NEXT index value if no exact match\n",
      " |          * nearest: use the NEAREST index value if no exact match. Tied\n",
      " |            distances are broken by preferring the larger index value.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance from index value for inexact matches. The value of\n",
      " |          the index at the matching location most satisfy the equation\n",
      " |          ``abs(index[loc] - key) <= tolerance``.\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      loc : int if unique index, possibly slice or mask if not\n",
      " |  \n",
      " |  get_slice_bound(self, label, side, kind)\n",
      " |      Calculate slice bound that corresponds to given label.\n",
      " |      \n",
      " |      Returns leftmost (one-past-the-rightmost if ``side=='right'``) position\n",
      " |      of given label.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |      side : {'left', 'right'}\n",
      " |      kind : {'ix', 'loc', 'getitem'}\n",
      " |  \n",
      " |  get_value(self, series, key)\n",
      " |      Fast lookup of value from 1-dimensional ndarray. Only use this if you\n",
      " |      know what you're doing\n",
      " |  \n",
      " |  get_values(self)\n",
      " |      return the underlying data as an ndarray\n",
      " |  \n",
      " |  groupby(self, to_groupby)\n",
      " |      Group the index labels by a given array of values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_groupby : array\n",
      " |          Values used to determine the groups.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      groups : dict\n",
      " |          {group name -> group labels}\n",
      " |  \n",
      " |  holds_integer(self)\n",
      " |  \n",
      " |  identical(self, other)\n",
      " |      Similar to equals, but check that other comparable attributes are\n",
      " |      also equal\n",
      " |  \n",
      " |  insert(self, loc, item)\n",
      " |      Make new Index inserting new item at location. Follows\n",
      " |      Python list.append semantics for negative values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int\n",
      " |      item : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      new_index : Index\n",
      " |  \n",
      " |  intersection(self, other)\n",
      " |      Form the intersection of two Index objects.\n",
      " |      \n",
      " |      This returns a new Index with elements common to the index and `other`.\n",
      " |      Sortedness of the result is not guaranteed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Index or array-like\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      intersection : Index\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> idx1 = pd.Index([1, 2, 3, 4])\n",
      " |      >>> idx2 = pd.Index([3, 4, 5, 6])\n",
      " |      >>> idx1.intersection(idx2)\n",
      " |      Int64Index([3, 4], dtype='int64')\n",
      " |  \n",
      " |  is_(self, other)\n",
      " |      More flexible, faster check like ``is`` but that works through views\n",
      " |      \n",
      " |      Note: this is *not* the same as ``Index.identical()``, which checks\n",
      " |      that metadata is also the same.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : object\n",
      " |          other object to compare against.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      True if both have same underlying data, False otherwise : bool\n",
      " |  \n",
      " |  is_boolean(self)\n",
      " |  \n",
      " |  is_categorical(self)\n",
      " |  \n",
      " |  is_floating(self)\n",
      " |  \n",
      " |  is_integer(self)\n",
      " |  \n",
      " |  is_lexsorted_for_tuple(self, tup)\n",
      " |  \n",
      " |  is_mixed(self)\n",
      " |  \n",
      " |  is_numeric(self)\n",
      " |  \n",
      " |  is_object(self)\n",
      " |  \n",
      " |  is_type_compatible(self, kind)\n",
      " |  \n",
      " |  isin(self, values, level=None)\n",
      " |      Compute boolean array of whether each index value is found in the\n",
      " |      passed set of values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : set or list-like\n",
      " |          Sought values.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |          Support for values as a set\n",
      " |      \n",
      " |      level : str or int, optional\n",
      " |          Name or position of the index level to use (if the index is a\n",
      " |          MultiIndex).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `level` is specified:\n",
      " |      \n",
      " |      - if it is the name of one *and only one* index level, use that level;\n",
      " |      - otherwise it should be a number indicating level position.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_contained : ndarray (boolean dtype)\n",
      " |  \n",
      " |  join(self, other, how='left', level=None, return_indexers=False)\n",
      " |      *this is an internal non-public method*\n",
      " |      \n",
      " |      Compute join_index and indexers to conform data\n",
      " |      structures to the new index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Index\n",
      " |      how : {'left', 'right', 'inner', 'outer'}\n",
      " |      level : int or level name, default None\n",
      " |      return_indexers : boolean, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      join_index, (left_indexer, right_indexer)\n",
      " |  \n",
      " |  map(self, mapper)\n",
      " |      Apply mapper function to its values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : callable\n",
      " |          Function to be applied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      applied : array\n",
      " |  \n",
      " |  order(self, return_indexer=False, ascending=True)\n",
      " |      Return sorted copy of Index\n",
      " |      \n",
      " |      DEPRECATED: use :meth:`Index.sort_values`\n",
      " |  \n",
      " |  putmask(self, mask, value)\n",
      " |      return a new Index of the values set with the mask\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.putmask\n",
      " |  \n",
      " |  ravel(self, order='C')\n",
      " |      return an ndarray of the flattened values of the underlying data\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.ravel\n",
      " |  \n",
      " |  reindex(self, target, method=None, level=None, limit=None, tolerance=None)\n",
      " |      Create index with target's values (move/add/delete values as necessary)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      target : an iterable\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      new_index : pd.Index\n",
      " |          Resulting index\n",
      " |      indexer : np.ndarray or None\n",
      " |          Indices of output values in original index\n",
      " |  \n",
      " |  rename(self, name, inplace=False)\n",
      " |      Set new names on index. Defaults to returning new index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str or list\n",
      " |          name to set\n",
      " |      inplace : bool\n",
      " |          if True, mutates in place\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      new index (of same type and class...etc) [if inplace, returns None]\n",
      " |  \n",
      " |  repeat(self, n, *args, **kwargs)\n",
      " |      Repeat elements of an Index. Refer to `numpy.ndarray.repeat`\n",
      " |      for more information about the `n` argument.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.repeat\n",
      " |  \n",
      " |  set_names(self, names, level=None, inplace=False)\n",
      " |      Set new names on index. Defaults to returning new index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      names : str or sequence\n",
      " |          name(s) to set\n",
      " |      level : int, level name, or sequence of int/level names (default None)\n",
      " |          If the index is a MultiIndex (hierarchical), level(s) to set (None\n",
      " |          for all levels).  Otherwise level must be None\n",
      " |      inplace : bool\n",
      " |          if True, mutates in place\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      new index (of same type and class...etc) [if inplace, returns None]\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> Index([1, 2, 3, 4]).set_names('foo')\n",
      " |      Int64Index([1, 2, 3, 4], dtype='int64')\n",
      " |      >>> Index([1, 2, 3, 4]).set_names(['foo'])\n",
      " |      Int64Index([1, 2, 3, 4], dtype='int64')\n",
      " |      >>> idx = MultiIndex.from_tuples([(1, u'one'), (1, u'two'),\n",
      " |                                        (2, u'one'), (2, u'two')],\n",
      " |                                        names=['foo', 'bar'])\n",
      " |      >>> idx.set_names(['baz', 'quz'])\n",
      " |      MultiIndex(levels=[[1, 2], [u'one', u'two']],\n",
      " |                 labels=[[0, 0, 1, 1], [0, 1, 0, 1]],\n",
      " |                 names=[u'baz', u'quz'])\n",
      " |      >>> idx.set_names('baz', level=0)\n",
      " |      MultiIndex(levels=[[1, 2], [u'one', u'two']],\n",
      " |                 labels=[[0, 0, 1, 1], [0, 1, 0, 1]],\n",
      " |                 names=[u'baz', u'bar'])\n",
      " |  \n",
      " |  set_value(self, arr, key, value)\n",
      " |      Fast lookup of value from 1-dimensional ndarray. Only use this if you\n",
      " |      know what you're doing\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None)\n",
      " |      Shift Index containing datetime objects by input number of periods and\n",
      " |      DateOffset\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Index\n",
      " |  \n",
      " |  slice_indexer(self, start=None, end=None, step=None, kind=None)\n",
      " |      For an ordered Index, compute the slice indexer for input labels and\n",
      " |      step\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start : label, default None\n",
      " |          If None, defaults to the beginning\n",
      " |      end : label, default None\n",
      " |          If None, defaults to the end\n",
      " |      step : int, default None\n",
      " |      kind : string, default None\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indexer : ndarray or slice\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function assumes that the data is sorted, so use at your own peril\n",
      " |  \n",
      " |  slice_locs(self, start=None, end=None, step=None, kind=None)\n",
      " |      Compute slice locations for input labels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start : label, default None\n",
      " |          If None, defaults to the beginning\n",
      " |      end : label, default None\n",
      " |          If None, defaults to the end\n",
      " |      step : int, defaults None\n",
      " |          If None, defaults to 1\n",
      " |      kind : {'ix', 'loc', 'getitem'} or None\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      start, end : int\n",
      " |  \n",
      " |  sort(self, *args, **kwargs)\n",
      " |  \n",
      " |  sort_values(self, return_indexer=False, ascending=True)\n",
      " |      Return sorted copy of Index\n",
      " |  \n",
      " |  sortlevel(self, level=None, ascending=True, sort_remaining=None)\n",
      " |      For internal compatibility with with the Index API\n",
      " |      \n",
      " |      Sort the Index. This is for compat with MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : boolean, default True\n",
      " |          False to sort in descending order\n",
      " |      \n",
      " |      level, sort_remaining are compat parameters\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted_index : Index\n",
      " |  \n",
      " |  summary(self, name=None)\n",
      " |  \n",
      " |  sym_diff = wrapper(*args, **kwargs)\n",
      " |  \n",
      " |  symmetric_difference(self, other, result_name=None)\n",
      " |      Compute the sorted symmetric difference of two Index objects.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Index or array-like\n",
      " |      result_name : str\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      symmetric_difference : Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``symmetric_difference`` contains elements that appear in either\n",
      " |      ``idx1`` or ``idx2`` but not both. Equivalent to the Index created by\n",
      " |      ``(idx1 - idx2) + (idx2 - idx1)`` with duplicates dropped.\n",
      " |      \n",
      " |      The sorting of a result containing ``NaN`` values is not guaranteed\n",
      " |      across Python versions. See GitHub issue #6444.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx1 = Index([1, 2, 3, 4])\n",
      " |      >>> idx2 = Index([2, 3, 4, 5])\n",
      " |      >>> idx1.symmetric_difference(idx2)\n",
      " |      Int64Index([1, 5], dtype='int64')\n",
      " |      \n",
      " |      You can also use the ``^`` operator:\n",
      " |      \n",
      " |      >>> idx1 ^ idx2\n",
      " |      Int64Index([1, 5], dtype='int64')\n",
      " |  \n",
      " |  take(self, indices, axis=0, allow_fill=True, fill_value=None, **kwargs)\n",
      " |      return a new %(klass)s of the values selected by the indices\n",
      " |      \n",
      " |      For internal compatibility with numpy arrays.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : list\n",
      " |          Indices to be taken\n",
      " |      axis : int, optional\n",
      " |          The axis over which to select values, always 0.\n",
      " |      allow_fill : bool, default True\n",
      " |      fill_value : bool, default None\n",
      " |          If allow_fill=True and fill_value is not None, indices specified by\n",
      " |          -1 is regarded as NA. If Index doesn't hold NA, raise ValueError\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.take\n",
      " |  \n",
      " |  to_datetime(self, dayfirst=False)\n",
      " |      For an Index containing strings or datetime.datetime objects, attempt\n",
      " |      conversion to DatetimeIndex\n",
      " |  \n",
      " |  to_native_types(self, slicer=None, **kwargs)\n",
      " |      slice and dice then format\n",
      " |  \n",
      " |  to_series(self, **kwargs)\n",
      " |      Create a Series with both index and values equal to the index keys\n",
      " |      useful with map for returning an indexer based on an index\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series : dtype will be based on the type of the Index values.\n",
      " |  \n",
      " |  tolist(self)\n",
      " |      return a list of the Index values\n",
      " |  \n",
      " |  union(self, other)\n",
      " |      Form the union of two Index objects and sorts if possible.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Index or array-like\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      union : Index\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> idx1 = pd.Index([1, 2, 3, 4])\n",
      " |      >>> idx2 = pd.Index([3, 4, 5, 6])\n",
      " |      >>> idx1.union(idx2)\n",
      " |      Int64Index([1, 2, 3, 4, 5, 6], dtype='int64')\n",
      " |  \n",
      " |  view(self, cls=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls, data=None, dtype=None, copy=False, name=None, fastpath=False, tupleize_cols=True, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dtype_str\n",
      " |  \n",
      " |  has_duplicates\n",
      " |  \n",
      " |  hasnans\n",
      " |  \n",
      " |  inferred_type\n",
      " |  \n",
      " |  is_all_dates\n",
      " |  \n",
      " |  is_monotonic\n",
      " |      alias for is_monotonic_increasing (deprecated)\n",
      " |  \n",
      " |  is_monotonic_decreasing\n",
      " |      return if the index is monotonic decreasing (only equal or\n",
      " |      decreasing) values.\n",
      " |  \n",
      " |  is_monotonic_increasing\n",
      " |      return if the index is monotonic increasing (only equal or\n",
      " |      increasing) values.\n",
      " |  \n",
      " |  is_unique\n",
      " |  \n",
      " |  names\n",
      " |  \n",
      " |  nlevels\n",
      " |  \n",
      " |  values\n",
      " |      return the underlying data as an ndarray\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  asi8 = None\n",
      " |  \n",
      " |  name = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  argmax(self, axis=None)\n",
      " |      return a ndarray of the maximum argument indexer\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.argmax\n",
      " |  \n",
      " |  argmin(self, axis=None)\n",
      " |      return a ndarray of the minimum argument indexer\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.argmin\n",
      " |  \n",
      " |  factorize(self, sort=False, na_sentinel=-1)\n",
      " |      Encode the object as an enumerated type or categorical variable\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sort : boolean, default False\n",
      " |          Sort by values\n",
      " |      na_sentinel: int, default -1\n",
      " |          Value to mark \"not found\"\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : the indexer to the original array\n",
      " |      uniques : the unique Index\n",
      " |  \n",
      " |  item(self)\n",
      " |      return the first element of the underlying data as a python\n",
      " |      scalar\n",
      " |  \n",
      " |  max(self)\n",
      " |      The maximum value of the object\n",
      " |  \n",
      " |  memory_usage(self, deep=False)\n",
      " |      Memory usage of my values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool\n",
      " |          Introspect the data deeply, interrogate\n",
      " |          `object` dtypes for system-level memory consumption\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes used\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Memory usage does not include memory consumed by elements that\n",
      " |      are not components of the array if deep=False\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes\n",
      " |  \n",
      " |  min(self)\n",
      " |      The minimum value of the object\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Return number of unique elements in the object.\n",
      " |      \n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the count.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique : int\n",
      " |  \n",
      " |  searchsorted(self, key, side='left', sorter=None)\n",
      " |      Find indices where elements should be inserted to maintain order.\n",
      " |      \n",
      " |      Find the indices into a sorted IndexOpsMixin `self` such that, if the\n",
      " |      corresponding elements in `v` were inserted before the indices, the\n",
      " |      order of `self` would be preserved.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : array_like\n",
      " |          Values to insert into `self`.\n",
      " |      side : {'left', 'right'}, optional\n",
      " |          If 'left', the index of the first suitable location found is given.\n",
      " |          If 'right', return the last such index.  If there is no suitable\n",
      " |          index, return either 0 or N (where N is the length of `self`).\n",
      " |      sorter : 1-D array_like, optional\n",
      " |          Optional array of integer indices that sort `self` into ascending\n",
      " |          order. They are typically the result of ``np.argsort``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indices : array of ints\n",
      " |          Array of insertion points with the same shape as `v`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.searchsorted\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Binary search is used to find the required insertion points.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = pd.Series([1, 2, 3])\n",
      " |      >>> x\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      >>> x.searchsorted(4)\n",
      " |      array([3])\n",
      " |      >>> x.searchsorted([0, 4])\n",
      " |      array([0, 3])\n",
      " |      >>> x.searchsorted([1, 3], side='left')\n",
      " |      array([0, 2])\n",
      " |      >>> x.searchsorted([1, 3], side='right')\n",
      " |      array([1, 3])\n",
      " |      >>>\n",
      " |      >>> x = pd.Categorical(['apple', 'bread', 'bread', 'cheese', 'milk' ])\n",
      " |      [apple, bread, bread, cheese, milk]\n",
      " |      Categories (4, object): [apple < bread < cheese < milk]\n",
      " |      >>> x.searchsorted('bread')\n",
      " |      array([1])     # Note: an array, not a scalar\n",
      " |      >>> x.searchsorted(['bread'])\n",
      " |      array([1])\n",
      " |      >>> x.searchsorted(['bread', 'eggs'])\n",
      " |      array([1, 4])\n",
      " |      >>> x.searchsorted(['bread', 'eggs'], side='right')\n",
      " |      array([3, 4])    # eggs before milk\n",
      " |  \n",
      " |  transpose(self, *args, **kwargs)\n",
      " |      return the transpose, which is by definition self\n",
      " |  \n",
      " |  unique(self)\n",
      " |      Return array of unique values in the object. Significantly faster than\n",
      " |      numpy.unique. Includes NA values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      uniques : ndarray\n",
      " |  \n",
      " |  value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
      " |      Returns object containing counts of unique values.\n",
      " |      \n",
      " |      The resulting object will be in descending order so that the\n",
      " |      first element is the most frequently-occurring element.\n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      normalize : boolean, default False\n",
      " |          If True then the object returned will contain the relative\n",
      " |          frequencies of the unique values.\n",
      " |      sort : boolean, default True\n",
      " |          Sort by values\n",
      " |      ascending : boolean, default False\n",
      " |          Sort in ascending order\n",
      " |      bins : integer, optional\n",
      " |          Rather than count values, group them into half-open bins,\n",
      " |          a convenience for pd.cut, only works with numeric data\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include counts of NaN.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      counts : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  T\n",
      " |      return the transpose, which is by definition self\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  base\n",
      " |      return the base object if the memory of the underlying data is\n",
      " |      shared\n",
      " |  \n",
      " |  data\n",
      " |      return the data pointer of the underlying data\n",
      " |  \n",
      " |  flags\n",
      " |      return the ndarray.flags for the underlying data\n",
      " |  \n",
      " |  itemsize\n",
      " |      return the size of the dtype of the item of the underlying data\n",
      " |  \n",
      " |  nbytes\n",
      " |      return the number of bytes in the underlying data\n",
      " |  \n",
      " |  ndim\n",
      " |      return the number of dimensions of the underlying data,\n",
      " |      by definition 1\n",
      " |  \n",
      " |  shape\n",
      " |      return a tuple of the shape of the underlying data\n",
      " |  \n",
      " |  size\n",
      " |      return the number of elements in the underlying data\n",
      " |  \n",
      " |  strides\n",
      " |      return the strides of the underlying data\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:\n",
      " |  \n",
      " |  str = <class 'pandas.core.strings.StringMethods'>\n",
      " |      Vectorized string functions for Series and Index. NAs stay NA unless\n",
      " |      handled otherwise by a particular method. Patterned after Python's string\n",
      " |      methods, with some inspiration from R's stringr package.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.str.split('_')\n",
      " |      >>> s.str.replace('_', '')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for a object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(obj.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64\n",
      "{'ndim': 1, 'name': 'ix', 'obj': a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64}\n",
      "1\n",
      "ix\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d, name=\"series\")\n",
    "print(obj)\n",
    "print(obj.ix.__dict__)\n",
    "print(obj.ix.ndim)\n",
    "print(obj.ix.name)\n",
    "print(obj.ix['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64\n",
      "{'ndim': 1, 'name': 'at', 'obj': a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64}\n",
      "1\n",
      "at\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d, name=\"series\")\n",
    "print(obj)\n",
    "print(obj.at.__dict__)\n",
    "print(obj.at.ndim)\n",
    "print(obj.at.name)\n",
    "print(obj.at['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64\n",
      "{'ndim': 1, 'name': 'iat', 'obj': a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64}\n",
      "1\n",
      "iat\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d, name=\"series\")\n",
    "print(obj)\n",
    "print(obj.iat.__dict__)\n",
    "print(obj.iat.ndim)\n",
    "print(obj.iat.name)\n",
    "print(obj.iat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64\n",
      "{'ndim': 1, 'name': 'loc', 'obj': a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64}\n",
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "Name: series, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d, name=\"series\")\n",
    "print(obj)\n",
    "print(obj.loc.__dict__)\n",
    "\n",
    "print(obj.loc['a':'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64\n",
      "{'ndim': 1, 'name': 'iloc', 'obj': a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64}\n",
      "a    1\n",
      "b    2\n",
      "Name: series, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d, name=\"series\")\n",
    "print(obj)\n",
    "print(obj.iloc.__dict__)\n",
    "\n",
    "print(obj.iloc[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_copy': None, '_data': BlockManager\n",
      "Items: Index(['series 1'], dtype='object')\n",
      "Axis 1: Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "IntBlock: slice(0, 1, 1), 1 x 4, dtype: int64, '_item_cache': {}}\n",
      "   series 1\n",
      "a         1\n",
      "b         2\n",
      "c         3\n",
      "d         4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj1 = pd.Series(d, name=\"series 1\")\n",
    "obj2 = pd.Series(d, name=\"series 2\")\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(obj1)\n",
    "print(df1.__dict__)\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_copy': None, '_data': BlockManager\n",
      "Items: Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "Axis 1: Index(['series 1', 'series 2'], dtype='object')\n",
      "IntBlock: slice(0, 4, 1), 4 x 2, dtype: int64, '_item_cache': {}}\n",
      "          a  b  c  d\n",
      "series 1  1  2  3  4\n",
      "series 2  1  2  3  4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj1 = pd.Series(d, name=\"series 1\")\n",
    "obj2 = pd.Series(d, name=\"series 2\")\n",
    "\n",
    "df2 = pd.DataFrame([obj1,obj2])\n",
    "print(df2.__dict__)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_copy': None, '_data': BlockManager\n",
      "Items: Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "Axis 1: Index(['series 1', 'series 2'], dtype='object')\n",
      "IntBlock: slice(0, 4, 1), 4 x 2, dtype: int64, '_item_cache': {}}\n",
      "Index(['series 1', 'series 2'], dtype='object')\n",
      "Index(['series 1', 'series 2'], dtype='object')\n",
      "Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "Index(['a', 'b', 'c', 'd'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj1 = pd.Series(d, name=\"series 1\")\n",
    "obj2 = pd.Series(d, name=\"series 2\")\n",
    "\n",
    "df2 = pd.DataFrame([obj1,obj2])\n",
    "print(df2.__dict__)\n",
    "print(df2.axes[0])\n",
    "print(df2.index)\n",
    "print(df2.axes[1])\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xa  xb  xc\n",
      "ya   0   1   2\n",
      "yb   3   4   5\n",
      "yc   6   7   8\n",
      "Index(['ya', 'yb', 'yc'], dtype='object')\n",
      "Index(['xa', 'xb', 'xc'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x = pd.Index(['xa','xb','xc'])\n",
    "y = pd.Index(['ya','yb','yc'])\n",
    "\n",
    "d = np.arange(9).reshape(3,3)\n",
    "df2 = pd.DataFrame(d, index=y, columns=x)\n",
    "print(df2)\n",
    "print(df2.index)\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x label\n",
      "['xa' 'xb' 'xc']\n",
      "object\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x = pd.Index(['xa','xb','xc'], name=\"x label\")\n",
    "\n",
    "print(x.name)\n",
    "print(x.values)\n",
    "print(x.dtype)\n",
    "print(x.ndim)\n",
    "print(x.nlevels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__init__',\n",
       " '__inv__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmul__',\n",
       " '__rpow__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_add_comparison_methods',\n",
       " '_add_logical_methods',\n",
       " '_add_logical_methods_disabled',\n",
       " '_add_numeric_methods',\n",
       " '_add_numeric_methods_binary',\n",
       " '_add_numeric_methods_disabled',\n",
       " '_add_numeric_methods_unary',\n",
       " '_add_numericlike_set_methods_disabled',\n",
       " '_allow_datetime_index_ops',\n",
       " '_allow_index_ops',\n",
       " '_allow_period_index_ops',\n",
       " '_arrmap',\n",
       " '_assert_can_do_op',\n",
       " '_assert_can_do_setop',\n",
       " '_assert_take_fillable',\n",
       " '_attributes',\n",
       " '_box_scalars',\n",
       " '_can_hold_na',\n",
       " '_can_reindex',\n",
       " '_cleanup',\n",
       " '_coerce_scalar_to_index',\n",
       " '_coerce_to_ndarray',\n",
       " '_comparables',\n",
       " '_constructor',\n",
       " '_convert_can_do_setop',\n",
       " '_convert_for_op',\n",
       " '_convert_list_indexer',\n",
       " '_convert_scalar_indexer',\n",
       " '_convert_slice_indexer',\n",
       " '_convert_tolerance',\n",
       " '_data',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_engine',\n",
       " '_engine_type',\n",
       " '_ensure_compat_append',\n",
       " '_ensure_compat_concat',\n",
       " '_evaluate_with_datetime_like',\n",
       " '_evaluate_with_timedelta_like',\n",
       " '_evalute_compare',\n",
       " '_filter_indexer_tolerance',\n",
       " '_format_attrs',\n",
       " '_format_data',\n",
       " '_format_native_types',\n",
       " '_format_space',\n",
       " '_format_with_header',\n",
       " '_formatter_func',\n",
       " '_get_attributes_dict',\n",
       " '_get_consensus_name',\n",
       " '_get_duplicates',\n",
       " '_get_fill_indexer',\n",
       " '_get_fill_indexer_searchsorted',\n",
       " '_get_level_number',\n",
       " '_get_names',\n",
       " '_get_nearest_indexer',\n",
       " '_groupby',\n",
       " '_has_complex_internals',\n",
       " '_id',\n",
       " '_infer_as_myclass',\n",
       " '_inner_indexer',\n",
       " '_invalid_indexer',\n",
       " '_is_numeric_dtype',\n",
       " '_isnan',\n",
       " '_join_level',\n",
       " '_join_monotonic',\n",
       " '_join_multi',\n",
       " '_join_non_unique',\n",
       " '_join_precedence',\n",
       " '_left_indexer',\n",
       " '_left_indexer_unique',\n",
       " '_make_str_accessor',\n",
       " '_maybe_cast_indexer',\n",
       " '_maybe_cast_slice_bound',\n",
       " '_maybe_update_attributes',\n",
       " '_mpl_repr',\n",
       " '_na_value',\n",
       " '_nan_idxs',\n",
       " '_outer_indexer',\n",
       " '_possibly_promote',\n",
       " '_reduce',\n",
       " '_reindex_non_unique',\n",
       " '_reset_cache',\n",
       " '_reset_identity',\n",
       " '_scalar_data_error',\n",
       " '_searchsorted_monotonic',\n",
       " '_set_names',\n",
       " '_shallow_copy',\n",
       " '_shallow_copy_with_infer',\n",
       " '_simple_new',\n",
       " '_string_data_error',\n",
       " '_to_embed',\n",
       " '_to_safe_for_reshape',\n",
       " '_typ',\n",
       " '_unpickle_compat',\n",
       " '_update_inplace',\n",
       " '_validate_for_numeric_binop',\n",
       " '_validate_for_numeric_unaryop',\n",
       " '_validate_index_level',\n",
       " '_validate_indexer',\n",
       " '_values',\n",
       " '_wrap_joined_index',\n",
       " '_wrap_union_result',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'asi8',\n",
       " 'asof',\n",
       " 'asof_locs',\n",
       " 'astype',\n",
       " 'base',\n",
       " 'copy',\n",
       " 'data',\n",
       " 'delete',\n",
       " 'diff',\n",
       " 'difference',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'dtype',\n",
       " 'dtype_str',\n",
       " 'duplicated',\n",
       " 'equals',\n",
       " 'factorize',\n",
       " 'fillna',\n",
       " 'flags',\n",
       " 'format',\n",
       " 'get_duplicates',\n",
       " 'get_indexer',\n",
       " 'get_indexer_for',\n",
       " 'get_indexer_non_unique',\n",
       " 'get_level_values',\n",
       " 'get_loc',\n",
       " 'get_slice_bound',\n",
       " 'get_value',\n",
       " 'get_values',\n",
       " 'groupby',\n",
       " 'has_duplicates',\n",
       " 'hasnans',\n",
       " 'holds_integer',\n",
       " 'identical',\n",
       " 'inferred_type',\n",
       " 'insert',\n",
       " 'intersection',\n",
       " 'is_',\n",
       " 'is_all_dates',\n",
       " 'is_boolean',\n",
       " 'is_categorical',\n",
       " 'is_floating',\n",
       " 'is_integer',\n",
       " 'is_lexsorted_for_tuple',\n",
       " 'is_mixed',\n",
       " 'is_monotonic',\n",
       " 'is_monotonic_decreasing',\n",
       " 'is_monotonic_increasing',\n",
       " 'is_numeric',\n",
       " 'is_object',\n",
       " 'is_type_compatible',\n",
       " 'is_unique',\n",
       " 'isin',\n",
       " 'item',\n",
       " 'itemsize',\n",
       " 'join',\n",
       " 'map',\n",
       " 'max',\n",
       " 'memory_usage',\n",
       " 'min',\n",
       " 'name',\n",
       " 'names',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'nlevels',\n",
       " 'nunique',\n",
       " 'order',\n",
       " 'putmask',\n",
       " 'ravel',\n",
       " 'reindex',\n",
       " 'rename',\n",
       " 'repeat',\n",
       " 'searchsorted',\n",
       " 'set_names',\n",
       " 'set_value',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'slice_indexer',\n",
       " 'slice_locs',\n",
       " 'sort',\n",
       " 'sort_values',\n",
       " 'sortlevel',\n",
       " 'str',\n",
       " 'strides',\n",
       " 'summary',\n",
       " 'sym_diff',\n",
       " 'symmetric_difference',\n",
       " 'take',\n",
       " 'to_datetime',\n",
       " 'to_native_types',\n",
       " 'to_series',\n",
       " 'tolist',\n",
       " 'transpose',\n",
       " 'union',\n",
       " 'unique',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'view']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pd.Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a  b  c  d\n",
      "series 1  1  2  3  4\n",
      "series 2  1  2  3  4\n",
      "1\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj1 = pd.Series(d, name=\"series 1\")\n",
    "obj2 = pd.Series(d, name=\"series 2\")\n",
    "\n",
    "df2 = pd.DataFrame([obj1,obj2])\n",
    "print(df2)\n",
    "print(df2.at[\"series 1\",'a'])\n",
    "print(type(df2.at[\"series 1\",'a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a  b  c  d\n",
      "series 1  1  2  3  4\n",
      "series 2  1  2  3  4\n",
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series 1, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "1\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj1 = pd.Series(d, name=\"series 1\")\n",
    "obj2 = pd.Series(d, name=\"series 2\")\n",
    "\n",
    "df2 = pd.DataFrame([obj1,obj2])\n",
    "print(df2)\n",
    "print(df2.loc[\"series 1\"])\n",
    "print(type(df2.loc[\"series 1\"]))\n",
    "print(df2.loc[\"series 1\",'a'])\n",
    "print(type(df2.loc[\"series 1\",'a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a  b  c  d\n",
      "series 1  1  2  3  4\n",
      "series 2  1  2  3  4\n",
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series 1, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "2\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj1 = pd.Series(d, name=\"series 1\")\n",
    "obj2 = pd.Series(d, name=\"series 2\")\n",
    "\n",
    "df2 = pd.DataFrame([obj1,obj2])\n",
    "print(df2)\n",
    "print(df2.ix[0])\n",
    "print(type(df2.ix[0]))\n",
    "print(df2.ix[0,1])\n",
    "print(type(df2.ix[0,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AAA  BBB  CCC\n",
      "0    4   10  100\n",
      "1    5   20   50\n",
      "2    6   30  -30\n",
      "3    7   40  -50\n",
      "   AAA  BBB  CCC\n",
      "0    4   10  100\n",
      "1    5   -1   50\n",
      "2    6   -1  -30\n",
      "3    7   -1  -50\n",
      "   AAA  BBB  CCC\n",
      "0    4   10  100\n",
      "1    5  555  555\n",
      "2    6  555  555\n",
      "3    7  555  555\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'AAA' : [4,5,6,7], \n",
    "        'BBB' : [10,20,30,40],\n",
    "        'CCC' : [100,50,-30,-50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "df.ix[df.AAA >= 5,'BBB'] = -1\n",
    "print(df)\n",
    "df.ix[df.AAA >= 5,['BBB','CCC']] = 555\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BBB  CCC  AAA\n",
      "0   10  100    4\n",
      "1   20   50    5\n",
      "2   30  -30    6\n",
      "3   40  -50    7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'AAA' : [4,5,6,7], \n",
    "        'BBB' : [10,20,30,40],\n",
    "        'CCC' : [100,50,-30,-50]}\n",
    "df = pd.DataFrame(data, columns=['BBB','CCC','AAA'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BBB  CCC  AAA\n",
      "a   10  100    4\n",
      "b   20   50    5\n",
      "c   30  -30    6\n",
      "d   40  -50    7\n",
      "a    4\n",
      "b    5\n",
      "c    6\n",
      "d    7\n",
      "Name: AAA, dtype: int64\n",
      "a    10\n",
      "b    20\n",
      "c    30\n",
      "d    40\n",
      "Name: BBB, dtype: int64\n",
      "a    100\n",
      "b     50\n",
      "c    -30\n",
      "d    -50\n",
      "Name: CCC, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'AAA' : [4,5,6,7], \n",
    "        'BBB' : [10,20,30,40],\n",
    "        'CCC' : [100,50,-30,-50]}\n",
    "df = pd.DataFrame(data, \n",
    "                  index=['a','b','c','d'], \n",
    "                  columns=list(data.keys()))\n",
    "print(df)\n",
    "#column 명으로 조회\n",
    "print(df.AAA)\n",
    "print(df.BBB)\n",
    "print(df.CCC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BBB  CCC  AAA\n",
      "a   10  100    4\n",
      "b   20   50    5\n",
      "c   30  -30    6\n",
      "d   40  -50    7\n",
      "a    999\n",
      "b    999\n",
      "c    999\n",
      "d    999\n",
      "Name: AAA, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'AAA' : [4,5,6,7], \n",
    "        'BBB' : [10,20,30,40],\n",
    "        'CCC' : [100,50,-30,-50]}\n",
    "df = pd.DataFrame(data, \n",
    "                  index=['a','b','c','d'], \n",
    "                  columns=list(data.keys()))\n",
    "print(df)\n",
    "#column 단위 갱신 \n",
    "df.AAA = 999\n",
    "print(df.AAA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BBB  CCC  AAA\n",
      "a   10  100    4\n",
      "b   20   50    5\n",
      "c   30  -30    6\n",
      "d   40  -50    7\n",
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "d    3\n",
      "Name: AAA, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'AAA' : [4,5,6,7], \n",
    "        'BBB' : [10,20,30,40],\n",
    "        'CCC' : [100,50,-30,-50]}\n",
    "df = pd.DataFrame(data, \n",
    "                  index=['a','b','c','d'], \n",
    "                  columns=list(data.keys()))\n",
    "print(df)\n",
    "#column 단위 갱신 \n",
    "df['AAA'] = np.arange(4)\n",
    "print(df.AAA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BBB  CCC  AAA\n",
      "a   10  100    4\n",
      "b   20   50    5\n",
      "c   30  -30    6\n",
      "d   40  -50    7\n",
      "   BBB  CCC  AAA    a\n",
      "a   10  100    4  999\n",
      "b   20   50    5  999\n",
      "c   30  -30    6  999\n",
      "d   40  -50    7  999\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'AAA' : [4,5,6,7], \n",
    "        'BBB' : [10,20,30,40],\n",
    "        'CCC' : [100,50,-30,-50]}\n",
    "df = pd.DataFrame(data, \n",
    "                  index=['a','b','c','d'], \n",
    "                  columns=list(data.keys()))\n",
    "print(df)\n",
    "#column 단위 갱신 \n",
    "df['a'] = 999\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AAA  BBB  CCC\n",
      "a    4   10  100\n",
      "b    5   20   50\n",
      "c    6   30  -30\n",
      "d    7   40  -50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'AAA' : {'a' : 4,'b':5, 'c':6, 'd':7}, \n",
    "        'BBB' : {'a': 10, 'b' : 20, 'c':30, 'd': 40},\n",
    "        'CCC' : {'a':100, 'b': 50, 'c': -30, 'd': -50} }\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BBB  CCC  AAA\n",
      "a   10  100    4\n",
      "b   20   50    5\n",
      "c   30  -30    6\n",
      "d   40  -50    7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'AAA' : [4,5,6,7], \n",
    "        'BBB' : [10,20,30,40],\n",
    "        'CCC' : [100,50,-30,-50]}\n",
    "df = pd.DataFrame(data, \n",
    "                  index=['a','b','c','d'], \n",
    "                  columns=list(data.keys()))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index does not support mutable operations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-936b593c08d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                   columns=list(data.keys()))\n\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'z'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Index does not support mutable operations\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Index does not support mutable operations"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'AAA' : [4,5,6,7], \n",
    "        'BBB' : [10,20,30,40],\n",
    "        'CCC' : [100,50,-30,-50]}\n",
    "df = pd.DataFrame(data, \n",
    "                  index=['a','b','c','d'], \n",
    "                  columns=list(data.keys()))\n",
    "\n",
    "df.index[0] = 'z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BBB  CCC  AAA\n",
      "a   10  100    4\n",
      "b   20   50    5\n",
      "c   30  -30    6\n",
      "d   40  -50    7\n",
      "Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "   BBB  CCC  AAA\n",
      "z   10  100    4\n",
      "x   20   50    5\n",
      "y   30  -30    6\n",
      "t   40  -50    7\n",
      "Index(['z', 'x', 'y', 't'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'AAA' : [4,5,6,7], \n",
    "        'BBB' : [10,20,30,40],\n",
    "        'CCC' : [100,50,-30,-50]}\n",
    "df = pd.DataFrame(data, \n",
    "                  index=['a','b','c','d'], \n",
    "                  columns=list(data.keys()))\n",
    "print(df)\n",
    "print(df.index)\n",
    "df.index = ['z','x','y','t']\n",
    "print(df)\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function date_range in module pandas.tseries.index:\n",
      "\n",
      "date_range(start=None, end=None, periods=None, freq='D', tz=None, normalize=False, name=None, closed=None, **kwargs)\n",
      "    Return a fixed frequency datetime index, with day (calendar) as the default\n",
      "    frequency\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    start : string or datetime-like, default None\n",
      "        Left bound for generating dates\n",
      "    end : string or datetime-like, default None\n",
      "        Right bound for generating dates\n",
      "    periods : integer or None, default None\n",
      "        If None, must specify start and end\n",
      "    freq : string or DateOffset, default 'D' (calendar daily)\n",
      "        Frequency strings can have multiples, e.g. '5H'\n",
      "    tz : string or None\n",
      "        Time zone name for returning localized DatetimeIndex, for example\n",
      "    Asia/Hong_Kong\n",
      "    normalize : bool, default False\n",
      "        Normalize start/end dates to midnight before generating date range\n",
      "    name : str, default None\n",
      "        Name of the resulting index\n",
      "    closed : string or None, default None\n",
      "        Make the interval closed with respect to the given frequency to\n",
      "        the 'left', 'right', or both sides (None)\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    2 of start, end, or periods must be specified\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    rng : DatetimeIndex\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2016-11-01', '2016-11-02', '2016-11-03'], dtype='datetime64[ns]', name='id', freq='D')\n",
      "[datetime.date(2016, 11, 1) datetime.date(2016, 11, 2)\n",
      " datetime.date(2016, 11, 3)]\n",
      "[2016 2016 2016]\n",
      "[11 11 11]\n",
      "[1 2 3]\n",
      "[0 0 0]\n",
      "[0 0 0]\n",
      "[0 0 0]\n",
      "[0 0 0]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "id = pd.Index(pd.date_range('2016-11-01',periods=3), name=\"id\")\n",
    "print(id)\n",
    "print(id.date)\n",
    "print(id.year)\n",
    "print(id.month)\n",
    "print(id.day)\n",
    "print(id.hour)\n",
    "print(id.minute)\n",
    "print(id.second)\n",
    "print(id.microsecond)\n",
    "print(id.nanosecond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2016-11-01', '2016-11-02', '2016-11-03'], dtype='int64', name='id', freq='D')\n",
      "[2016 2016 2016]\n",
      "[11 11 11]\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "id = pd.Index(pd.period_range('2016-11-01',periods=3), name=\"id\")\n",
    "print(id)\n",
    "\n",
    "print(id.year)\n",
    "print(id.month)\n",
    "print(id.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    f   g   h   i\n",
      "a   0   2   4   6\n",
      "b   8  10  12  14\n",
      "c  16  18  20  22\n",
      "d  24  26  28  30\n",
      "   f  g  h  i\n",
      "a  0  0  0  0\n",
      "b  0  0  0  0\n",
      "c  0  0  0  0\n",
      "d  0  0  0  0\n",
      "     f    g    h    i\n",
      "a    0    1    4    9\n",
      "b   16   25   36   49\n",
      "c   64   81  100  121\n",
      "d  144  169  196  225\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.arange(16).reshape(4,4), \n",
    "                  index=['a','b','c','d'],\n",
    "                  columns=['f','g','h','i'])\n",
    "    \n",
    "print(df.add(df))\n",
    "print(df.sub(df))\n",
    "print(df.mul(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     f    g    h    i\n",
      "a  NaN  1.0  1.0  1.0\n",
      "b  1.0  1.0  1.0  1.0\n",
      "c  1.0  1.0  1.0  1.0\n",
      "d  1.0  1.0  1.0  1.0\n",
      "     f    g    h    i\n",
      "a  NaN  1.0  1.0  1.0\n",
      "b  1.0  1.0  1.0  1.0\n",
      "c  1.0  1.0  1.0  1.0\n",
      "d  1.0  1.0  1.0  1.0\n",
      "     f    g    h    i\n",
      "a  NaN  0.0  0.0  0.0\n",
      "b  0.0  0.0  0.0  0.0\n",
      "c  0.0  0.0  0.0  0.0\n",
      "d  0.0  0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.arange(16).reshape(4,4), \n",
    "                  index=['a','b','c','d'],\n",
    "                  columns=['f','g','h','i'])\n",
    "    \n",
    "print(df.truediv(df))\n",
    "print(df.floordiv(df))\n",
    "print(df.mod(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    f   g   h   i\n",
      "d  12  13  14  15\n",
      "c   8   9  10  11\n",
      "b   4   5   6   7\n",
      "a   0   1   2   3\n",
      "e   0   0   0   0\n",
      "['d', 'c', 'b', 'a']\n",
      "    f   g   h   i\n",
      "d  12  13  14  15\n",
      "c   8   9  10  11\n",
      "b   4   5   6   7\n",
      "a   0   1   2   3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.arange(16).reshape(4,4), \n",
    "                  index=['a','b','c','d'],\n",
    "                  columns=['f','g','h','i'])\n",
    "\n",
    "print(df.reindex([\"d\",\"c\",\"b\",\"a\",\"e\"], fill_value=0))\n",
    "lr = list(df.index)\n",
    "lr.reverse()\n",
    "print(lr)\n",
    "print(df.reindex(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    b\n",
      "2    a\n",
      "4    c\n",
      "dtype: object\n",
      "0      b\n",
      "1    NaN\n",
      "2      a\n",
      "3    NaN\n",
      "4      c\n",
      "5    NaN\n",
      "dtype: object\n",
      "0    b\n",
      "1    b\n",
      "2    a\n",
      "3    a\n",
      "4    c\n",
      "5    c\n",
      "dtype: object\n",
      "0      b\n",
      "1      a\n",
      "2      a\n",
      "3      c\n",
      "4      c\n",
      "5    NaN\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "obj = pd.Series(['b','a','c'], index=[0,2,4])\n",
    "print(obj)\n",
    "\n",
    "obj1 = obj.reindex(np.arange(6))\n",
    "print(obj1)\n",
    "\n",
    "obj1 = obj.reindex(np.arange(6), method='ffill')\n",
    "print(obj1)\n",
    "obj1 = obj.reindex(np.arange(6), method='bfill')\n",
    "print(obj1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    f   g   h   i\n",
      "a   0   1   2   3\n",
      "b   4   5   6   7\n",
      "c   8   9  10  11\n",
      "d  12  13  14  15\n",
      "    f  c   g   h\n",
      "a   0  0   1   2\n",
      "b   4  0   5   6\n",
      "c   8  0   9  10\n",
      "d  12  0  13  14\n",
      "    f   g   h   i\n",
      "a   0   1   2   3\n",
      "c   8   9  10  11\n",
      "e   0   0   0   0\n",
      "d  12  13  14  15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.arange(16).reshape(4,4), \n",
    "                  index=['a','b','c','d'],\n",
    "                  columns=['f','g','h','i'])\n",
    "print(df)\n",
    "print(df.reindex( columns=[\"f\",\"c\",\"g\",\"h\"],fill_value=0))\n",
    "print(df.reindex( index=[\"a\",\"c\",\"e\",\"d\"],fill_value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method reindex in module pandas.core.frame:\n",
      "\n",
      "reindex(index=None, columns=None, **kwargs) method of pandas.core.frame.DataFrame instance\n",
      "    Conform DataFrame to new index with optional filling logic, placing\n",
      "    NA/NaN in locations having no value in the previous index. A new object\n",
      "    is produced unless the new index is equivalent to the current one and\n",
      "    copy=False\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    index, columns : array-like, optional (can be specified in order, or as\n",
      "        keywords)\n",
      "        New labels / index to conform to. Preferably an Index object to\n",
      "        avoid duplicating data\n",
      "    method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      "        method to use for filling holes in reindexed DataFrame.\n",
      "        Please note: this is only  applicable to DataFrames/Series with a\n",
      "        monotonically increasing/decreasing index.\n",
      "    \n",
      "        * default: don't fill gaps\n",
      "        * pad / ffill: propagate last valid observation forward to next\n",
      "          valid\n",
      "        * backfill / bfill: use next valid observation to fill gap\n",
      "        * nearest: use nearest valid observations to fill gap\n",
      "    \n",
      "    copy : boolean, default True\n",
      "        Return a new object, even if the passed indexes are the same\n",
      "    level : int or name\n",
      "        Broadcast across a level, matching Index values on the\n",
      "        passed MultiIndex level\n",
      "    fill_value : scalar, default np.NaN\n",
      "        Value to use for missing values. Defaults to NaN, but can be any\n",
      "        \"compatible\" value\n",
      "    limit : int, default None\n",
      "        Maximum number of consecutive elements to forward or backward fill\n",
      "    tolerance : optional\n",
      "        Maximum distance between original and new labels for inexact\n",
      "        matches. The values of the index at the matching locations most\n",
      "        satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      "    \n",
      "        .. versionadded:: 0.17.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    Create a dataframe with some fictional data.\n",
      "    \n",
      "    >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      "    >>> df = pd.DataFrame({\n",
      "    ...      'http_status': [200,200,404,404,301],\n",
      "    ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      "    ...       index=index)\n",
      "    >>> df\n",
      "                http_status  response_time\n",
      "    Firefox            200           0.04\n",
      "    Chrome             200           0.02\n",
      "    Safari             404           0.07\n",
      "    IE10               404           0.08\n",
      "    Konqueror          301           1.00\n",
      "    \n",
      "    Create a new index and reindex the dataframe. By default\n",
      "    values in the new index that do not have corresponding\n",
      "    records in the dataframe are assigned ``NaN``.\n",
      "    \n",
      "    >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      "    ...             'Chrome']\n",
      "    >>> df.reindex(new_index)\n",
      "                   http_status  response_time\n",
      "    Safari                 404           0.07\n",
      "    Iceweasel              NaN            NaN\n",
      "    Comodo Dragon          NaN            NaN\n",
      "    IE10                   404           0.08\n",
      "    Chrome                 200           0.02\n",
      "    \n",
      "    We can fill in the missing values by passing a value to\n",
      "    the keyword ``fill_value``. Because the index is not monotonically\n",
      "    increasing or decreasing, we cannot use arguments to the keyword\n",
      "    ``method`` to fill the ``NaN`` values.\n",
      "    \n",
      "    >>> df.reindex(new_index, fill_value=0)\n",
      "                   http_status  response_time\n",
      "    Safari                 404           0.07\n",
      "    Iceweasel                0           0.00\n",
      "    Comodo Dragon            0           0.00\n",
      "    IE10                   404           0.08\n",
      "    Chrome                 200           0.02\n",
      "    \n",
      "    >>> df.reindex(new_index, fill_value='missing')\n",
      "                  http_status response_time\n",
      "    Safari                404          0.07\n",
      "    Iceweasel         missing       missing\n",
      "    Comodo Dragon     missing       missing\n",
      "    IE10                  404          0.08\n",
      "    Chrome                200          0.02\n",
      "    \n",
      "    To further illustrate the filling functionality in\n",
      "    ``reindex``, we will create a dataframe with a\n",
      "    monotonically increasing index (for example, a sequence\n",
      "    of dates).\n",
      "    \n",
      "    >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      "    >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      "    ...                    index=date_index)\n",
      "    >>> df2\n",
      "                prices\n",
      "    2010-01-01     100\n",
      "    2010-01-02     101\n",
      "    2010-01-03     NaN\n",
      "    2010-01-04     100\n",
      "    2010-01-05      89\n",
      "    2010-01-06      88\n",
      "    \n",
      "    Suppose we decide to expand the dataframe to cover a wider\n",
      "    date range.\n",
      "    \n",
      "    >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      "    >>> df2.reindex(date_index2)\n",
      "                prices\n",
      "    2009-12-29     NaN\n",
      "    2009-12-30     NaN\n",
      "    2009-12-31     NaN\n",
      "    2010-01-01     100\n",
      "    2010-01-02     101\n",
      "    2010-01-03     NaN\n",
      "    2010-01-04     100\n",
      "    2010-01-05      89\n",
      "    2010-01-06      88\n",
      "    2010-01-07     NaN\n",
      "    \n",
      "    The index entries that did not have a value in the original data frame\n",
      "    (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      "    If desired, we can fill in the missing values using one of several\n",
      "    options.\n",
      "    \n",
      "    For example, to backpropagate the last valid value to fill the ``NaN``\n",
      "    values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      "    \n",
      "    >>> df2.reindex(date_index2, method='bfill')\n",
      "                prices\n",
      "    2009-12-29     100\n",
      "    2009-12-30     100\n",
      "    2009-12-31     100\n",
      "    2010-01-01     100\n",
      "    2010-01-02     101\n",
      "    2010-01-03     NaN\n",
      "    2010-01-04     100\n",
      "    2010-01-05      89\n",
      "    2010-01-06      88\n",
      "    2010-01-07     NaN\n",
      "    \n",
      "    Please note that the ``NaN`` value present in the original dataframe\n",
      "    (at index value 2010-01-03) will not be filled by any of the\n",
      "    value propagation schemes. This is because filling while reindexing\n",
      "    does not look at dataframe values, but only compares the original and\n",
      "    desired indexes. If you do want to fill in the ``NaN`` values present\n",
      "    in the original dataframe, use the ``fillna()`` method.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    reindexed : DataFrame\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.reindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pow\n",
      "to_csv\n",
      "drop_duplicates\n",
      "dropna\n",
      "all\n",
      "idxmin\n",
      "rsub\n",
      "idxmax\n",
      "kurtosis\n",
      "mode\n",
      "rpow\n",
      "to_dict\n",
      "update\n",
      "multiply\n",
      "from_csv\n",
      "mod\n",
      "diff\n",
      "mad\n",
      "iteritems\n",
      "sem\n",
      "plot\n",
      "lt\n",
      "nlargest\n",
      "memory_usage\n",
      "floordiv\n",
      "cov\n",
      "align\n",
      "sub\n",
      "sort_values\n",
      "reindex_axis\n",
      "shift\n",
      "median\n",
      "reorder_levels\n",
      "divide\n",
      "reindex\n",
      "sort\n",
      "rtruediv\n",
      "min\n",
      "prod\n",
      "rmul\n",
      "kurt\n",
      "quantile\n",
      "sum\n",
      "reset_index\n",
      "to_timestamp\n",
      "irow\n",
      "max\n",
      "any\n",
      "eq\n",
      "rename\n",
      "radd\n",
      "rdiv\n",
      "truediv\n",
      "expanding\n",
      "round\n",
      "cumsum\n",
      "ge\n",
      "swaplevel\n",
      "rolling\n",
      "hist\n",
      "last_valid_index\n",
      "apply\n",
      "index\n",
      "items\n",
      "sortlevel\n",
      "unstack\n",
      "le\n",
      "to_period\n",
      "cumprod\n",
      "ewm\n",
      "gt\n",
      "axes\n",
      "mean\n",
      "append\n",
      "fillna\n",
      "get_value\n",
      "dot\n",
      "subtract\n",
      "compound\n",
      "rfloordiv\n",
      "to_string\n",
      "to_sparse\n",
      "count\n",
      "skew\n",
      "var\n",
      "ne\n",
      "std\n",
      "add\n",
      "cummax\n",
      "first_valid_index\n",
      "combine_first\n",
      "duplicated\n",
      "set_value\n",
      "div\n",
      "cummin\n",
      "corr\n",
      "combine\n",
      "iget_value\n",
      "rmod\n",
      "mul\n",
      "product\n",
      "sort_index\n",
      "isin\n",
      "nsmallest\n"
     ]
    }
   ],
   "source": [
    "a = set(pd.Series.__dict__)\n",
    "b = set(pd.DataFrame.__dict__)\n",
    "\n",
    "ab = a & b\n",
    "for i in list(ab) :\n",
    "    if i.startswith(\"_\") :\n",
    "        pass\n",
    "    else :\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function replace in module pandas.core.generic:\n",
      "\n",
      "replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad', axis=None)\n",
      "    Replace values given in 'to_replace' with 'value'.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    to_replace : str, regex, list, dict, Series, numeric, or None\n",
      "    \n",
      "        * str or regex:\n",
      "    \n",
      "            - str: string exactly matching `to_replace` will be replaced\n",
      "              with `value`\n",
      "            - regex: regexs matching `to_replace` will be replaced with\n",
      "              `value`\n",
      "    \n",
      "        * list of str, regex, or numeric:\n",
      "    \n",
      "            - First, if `to_replace` and `value` are both lists, they\n",
      "              **must** be the same length.\n",
      "            - Second, if ``regex=True`` then all of the strings in **both**\n",
      "              lists will be interpreted as regexs otherwise they will match\n",
      "              directly. This doesn't matter much for `value` since there\n",
      "              are only a few possible substitution regexes you can use.\n",
      "            - str and regex rules apply as above.\n",
      "    \n",
      "        * dict:\n",
      "    \n",
      "            - Nested dictionaries, e.g., {'a': {'b': nan}}, are read as\n",
      "              follows: look in column 'a' for the value 'b' and replace it\n",
      "              with nan. You can nest regular expressions as well. Note that\n",
      "              column names (the top-level dictionary keys in a nested\n",
      "              dictionary) **cannot** be regular expressions.\n",
      "            - Keys map to column names and values map to substitution\n",
      "              values. You can treat this as a special case of passing two\n",
      "              lists except that you are specifying the column to search in.\n",
      "    \n",
      "        * None:\n",
      "    \n",
      "            - This means that the ``regex`` argument must be a string,\n",
      "              compiled regular expression, or list, dict, ndarray or Series\n",
      "              of such elements. If `value` is also ``None`` then this\n",
      "              **must** be a nested dictionary or ``Series``.\n",
      "    \n",
      "        See the examples section for examples of each of these.\n",
      "    value : scalar, dict, list, str, regex, default None\n",
      "        Value to use to fill holes (e.g. 0), alternately a dict of values\n",
      "        specifying which value to use for each column (columns not in the\n",
      "        dict will not be filled). Regular expressions, strings and lists or\n",
      "        dicts of such objects are also allowed.\n",
      "    inplace : boolean, default False\n",
      "        If True, in place. Note: this will modify any\n",
      "        other views on this object (e.g. a column form a DataFrame).\n",
      "        Returns the caller if this is True.\n",
      "    limit : int, default None\n",
      "        Maximum size gap to forward or backward fill\n",
      "    regex : bool or same types as `to_replace`, default False\n",
      "        Whether to interpret `to_replace` and/or `value` as regular\n",
      "        expressions. If this is ``True`` then `to_replace` *must* be a\n",
      "        string. Otherwise, `to_replace` must be ``None`` because this\n",
      "        parameter will be interpreted as a regular expression or a list,\n",
      "        dict, or array of regular expressions.\n",
      "    method : string, optional, {'pad', 'ffill', 'bfill'}\n",
      "        The method to use when for replacement, when ``to_replace`` is a\n",
      "        ``list``.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    NDFrame.reindex\n",
      "    NDFrame.asfreq\n",
      "    NDFrame.fillna\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    filled : NDFrame\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    AssertionError\n",
      "        * If `regex` is not a ``bool`` and `to_replace` is not ``None``.\n",
      "    TypeError\n",
      "        * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      "          ``dict``, ``ndarray``, or ``Series``\n",
      "        * If `to_replace` is ``None`` and `regex` is not compilable into a\n",
      "          regular expression or is a list, dict, ndarray, or Series.\n",
      "    ValueError\n",
      "        * If `to_replace` and `value` are ``list`` s or ``ndarray`` s, but\n",
      "          they are not the same length.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    * Regex substitution is performed under the hood with ``re.sub``. The\n",
      "      rules for substitution for ``re.sub`` are the same.\n",
      "    * Regular expressions will only substitute on strings, meaning you\n",
      "      cannot provide, for example, a regular expression matching floating\n",
      "      point numbers and expect the columns in your frame that have a\n",
      "      numeric dtype to be matched. However, if those floating point numbers\n",
      "      *are* strings, then you can do this.\n",
      "    * This method has *a lot* of options. You are encouraged to experiment\n",
      "      and play with this method to gain intuition about how it works.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    f   g   h   i\n",
      "a   0   1   2   3\n",
      "b   4   5   6   7\n",
      "c   8   9  10  11\n",
      "d  12  13  14  15\n",
      "    f   g   h   i\n",
      "c   8   9  10  11\n",
      "d  12  13  14  15\n",
      "    h   i\n",
      "a   2   3\n",
      "b   6   7\n",
      "c  10  11\n",
      "d  14  15\n",
      "    f   g   h   i\n",
      "a   0   1   2   3\n",
      "b   4   5   6   7\n",
      "c   8   9  10  11\n",
      "d  12  13  14  15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.arange(16).reshape(4,4), \n",
    "                  index=['a','b','c','d'],\n",
    "                  columns=['f','g','h','i'])\n",
    "print(df)\n",
    "print(df.drop(['a','b']))\n",
    "\n",
    "print(df.drop(['f','g'],axis=1))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "d    3\n",
      "dtype: int32\n",
      "c    2\n",
      "d    3\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.Series(np.arange(4), \n",
    "                  index=['a','b','c','d'])\n",
    "print(df)\n",
    "print(df.drop(['a','b']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=4, step=1)\n",
      "Int64Index([0, 1, 2, 3], dtype='int64')\n",
      "Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sr = pd.Series(np.arange(4))\n",
    "\n",
    "sr1 = pd.Series(np.arange(4),index=[0,1,2,3])\n",
    "\n",
    "sr2 = pd.Series(np.arange(4), \n",
    "                  index=['a','b','c','d'])\n",
    "\n",
    "print(sr.index)\n",
    "print(sr1.index)\n",
    "print(sr2.index)\n",
    "\n",
    "print(sr[0])\n",
    "print(sr1[0])\n",
    "print(sr2[0])\n",
    "print(sr2['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    f   g   h   i\n",
      "0   0   1   2   3\n",
      "1   4   5   6   7\n",
      "2   8   9  10  11\n",
      "3  12  13  14  15\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'a'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-f3779516a170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                   columns=['f','g','h','i'])\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'a'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.arange(16).reshape(4,4), \n",
    "                  columns=['f','g','h','i'])\n",
    "print(df)\n",
    "print(df['a'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    f   g   h   i\n",
      "0   0   1   2   3\n",
      "1   4   5   6   7\n",
      "2   8   9  10  11\n",
      "3  12  13  14  15\n",
      "None\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.arange(16).reshape(4,4), \n",
    "                  columns=['f','g','h','i'])\n",
    "print(df)\n",
    "print(df.get('a'))\n",
    "print(df.get('b', np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "d    3\n",
      "e    4\n",
      "dtype: int32\n",
      "a    0\n",
      "c    2\n",
      "d    3\n",
      "dtype: int32\n",
      "a    0\n",
      "c    2\n",
      "d    3\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series(np.arange(5),index=['a','b','c','d','e'],dtype=np.int_)\n",
    "print(a)\n",
    "print(a.ix[[0,2,3]])\n",
    "print(a.ix[['a','c','d']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "d    3\n",
      "e    4\n",
      "dtype: int32\n",
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "dtype: int32\n",
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "d    3\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series(np.arange(5),index=['a','b','c','d','e'],dtype=np.int_)\n",
    "print(a)\n",
    "print(a.ix[:3])\n",
    "print(a.ix[:'d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'pandas.core.indexing._IXIndexer'>\n",
      "<class 'pandas.core.indexing._iAtIndexer'>\n",
      "<class 'pandas.core.indexing._iLocIndexer'>\n",
      "<class 'pandas.core.indexing._AtIndexer'>\n",
      "<class 'pandas.core.indexing._LocIndexer'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series(np.arange(5),index=['a','b','c','d','e'],dtype=np.int_)\n",
    "\n",
    "\n",
    "print(type(a.blocks))\n",
    "#A primarily label-location based indexer, with integer position fallback.\n",
    "print(type(a.ix))\n",
    "#Fast integer location scalar accessor.\n",
    "print(type(a.iat))\n",
    "#Purely integer-location based indexing for selection by position.\n",
    "print(type(a.iloc))\n",
    "\n",
    "#Fast label-based scalar accessor\n",
    "print(type(a.at))\n",
    "#Purely label-location based indexer for selection by label.\n",
    "print(type(a.loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   c1  c2  c3  c4\n",
      "a   2   6   7   9\n",
      "b  10  11   0   1\n",
      "c   3   5   4   8\n",
      "   c1  c2  c3  c4\n",
      "a   2   6   7   9\n",
      "c   3   5   4   8\n",
      "b  10  11   0   1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "l= [2,6,7,9,10,11,0,1,3,5,4,8]\n",
    "nl = np.array(l).reshape(3,4)\n",
    "a = pd.DataFrame(nl,index=['a','b','c'],\n",
    "              columns=['c1','c2','c3','c4'],dtype=np.int_)\n",
    "print(a)\n",
    "print(a.sort_values(by='c1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2013-01-01 -0.116887  2.213891  1.251784  0.412066\n",
      "2013-01-02 -0.615050  0.191062  0.726987  0.110455\n",
      "2013-01-03  1.633688 -0.457395  2.027202 -0.362281\n",
      "2013-01-04  1.591048 -0.297700 -1.119257  1.027640\n",
      "2013-01-05  1.126201  1.701021  0.447987 -0.759926\n",
      "2013-01-06 -0.078917  1.940938 -1.080131  0.944489\n",
      "                   D         C         B         A\n",
      "2013-01-01  0.412066  1.251784  2.213891 -0.116887\n",
      "2013-01-02  0.110455  0.726987  0.191062 -0.615050\n",
      "2013-01-03 -0.362281  2.027202 -0.457395  1.633688\n",
      "2013-01-04  1.027640 -1.119257 -0.297700  1.591048\n",
      "2013-01-05 -0.759926  0.447987  1.701021  1.126201\n",
      "2013-01-06  0.944489 -1.080131  1.940938 -0.078917\n",
      "                   A         B         C         D\n",
      "2013-01-06 -0.078917  1.940938 -1.080131  0.944489\n",
      "2013-01-05  1.126201  1.701021  0.447987 -0.759926\n",
      "2013-01-04  1.591048 -0.297700 -1.119257  1.027640\n",
      "2013-01-03  1.633688 -0.457395  2.027202 -0.362281\n",
      "2013-01-02 -0.615050  0.191062  0.726987  0.110455\n",
      "2013-01-01 -0.116887  2.213891  1.251784  0.412066\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dates = pd.date_range('20130101', periods=6)\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "print(df)\n",
    "print(df.sort_index(axis=1, ascending=False))\n",
    "print(df.sort_index(axis=0, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "d    3\n",
      "e    4\n",
      "dtype: int32\n",
      "a    0.0\n",
      "b    1.0\n",
      "c    2.0\n",
      "d    3.0\n",
      "e    4.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series(np.arange(5),index=['a','b','c','d','e'],dtype=np.int_)\n",
    "print(a)\n",
    "print(a.astype(np.float_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "a    True\n",
      "b    True\n",
      "c    True\n",
      "d    True\n",
      "e    True\n",
      "dtype: bool\n",
      "a    1\n",
      "b    1\n",
      "c    1\n",
      "d    2\n",
      "e    2\n",
      "dtype: int32\n",
      "0    1\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series([1,1,1,2,2],index=['a','b','c','d','e'],dtype=np.int_)\n",
    "b = a.copy()\n",
    "print(a is b)\n",
    "print(a == b)\n",
    "print(a)\n",
    "print(a.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method mode in module pandas.core.series:\n",
      "\n",
      "mode() method of pandas.core.series.Series instance\n",
      "    Returns the mode(s) of the dataset.\n",
      "    \n",
      "    Empty if nothing occurs at least 2 times.  Always returns Series even\n",
      "    if only one value.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    sort : bool, default True\n",
      "        If True, will lexicographically sort values, if False skips\n",
      "        sorting. Result ordering when ``sort=False`` is not defined.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    modes : Series (sorted)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(a.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  NaN\n",
      "3  2.0\n",
      "4  1.0\n",
      "5  2.0\n",
      "6  3.0\n",
      "A    6\n",
      "dtype: int64\n",
      "A    7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 2, 1, 2, 3]})\n",
    "print(df)\n",
    "print(df.count())\n",
    "\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3, 2, 1, 2, 3]})\n",
    "print(df1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  NaN\n",
      "3  2.0\n",
      "4  1.0\n",
      "5  2.0\n",
      "6  3.0\n",
      "element  1.0\n",
      "      A\n",
      "0   1.0\n",
      "1   2.0\n",
      "2  99.0\n",
      "3   2.0\n",
      "4   1.0\n",
      "5   2.0\n",
      "6   3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 2, 1, 2, 3]})\n",
    "print(df)\n",
    "print(\"element \",df.get_value(0,'A'))\n",
    "print(df.set_value(2,'A',99))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_value in module pandas.core.frame:\n",
      "\n",
      "get_value(index, col, takeable=False) method of pandas.core.frame.DataFrame instance\n",
      "    Quickly retrieve single value at passed column and index\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    index : row label\n",
      "    col : column label\n",
      "    takeable : interpret the index/col as indexers, default False\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    value : scalar value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.get_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element  1\n",
      "a     1\n",
      "b    99\n",
      "c     1\n",
      "d     2\n",
      "e     2\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series([1,1,1,2,2],index=['a','b','c','d','e'],dtype=np.int_)\n",
    "print(\"element \",a.get_value('a'))\n",
    "print(a.set_value('b',99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x00000000067D6CC8>\n",
      "a 1\n",
      "b 1\n",
      "c 1\n",
      "d 2\n",
      "e 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series([\"aaa\",\"bbb\",\"ccc\",\"ddd\",\"eee\"],index=['a','b','c','d','e'],dtype=np.int_)\n",
    "\n",
    "print(a.iteritems())\n",
    "for i,v in a.iteritems() :\n",
    "    print(i,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'itertuples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-326-6920fc18cbcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2670\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'itertuples'"
     ]
    }
   ],
   "source": [
    "a.itertuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0  aaa\n",
      "1  bbb\n",
      "2  ccc\n",
      "3  ddd\n",
      "4  eee\n",
      "<pandas.core.strings.StringMethods object at 0x00000000065C56D8>\n",
      "0    3\n",
      "1    3\n",
      "2    3\n",
      "3    3\n",
      "4    3\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.DataFrame([\"aaa\",\"bbb\",\"ccc\",\"ddd\",\"eee\"])\n",
    "print(a)\n",
    "print(a[0].str)\n",
    "print(a[0].str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n",
      "b    bbb\n",
      "c    ccc\n",
      "d    ddd\n",
      "e    eee\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series([\"aaa\",\"bbb\",\"ccc\",\"ddd\",\"eee\"],index=['a','b','c','d','e'])\n",
    "\n",
    "print(a.pop('a'))\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method pop in module pandas.core.generic:\n",
      "\n",
      "pop(item) method of pandas.core.series.Series instance\n",
      "    Return item and drop from frame. Raise KeyError if not found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(a.pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  4\n",
      "4  5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unorderable types: str() < int()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-359-e398c12f44b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'd'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'e'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'f'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ffill'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, columns, **kwargs)\u001b[0m\n\u001b[1;32m   2739\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2740\u001b[0m         return super(DataFrame, self).reindex(index=index, columns=columns,\n\u001b[0;32m-> 2741\u001b[0;31m                                               **kwargs)\n\u001b[0m\u001b[1;32m   2742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reindex_axis'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         return self._reindex_axes(axes, level, limit, tolerance, method,\n\u001b[0;32m-> 2229\u001b[0;31m                                   fill_value, copy).__finalize__(self)\n\u001b[0m\u001b[1;32m   2230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m     def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   2685\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2686\u001b[0m             frame = frame._reindex_index(index, method, copy, level,\n\u001b[0;32m-> 2687\u001b[0;31m                                          fill_value, limit, tolerance)\n\u001b[0m\u001b[1;32m   2688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_index\u001b[0;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         new_index, indexer = self.index.reindex(new_index, method, level,\n\u001b[1;32m   2694\u001b[0m                                                 \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m                                                 tolerance=tolerance)\n\u001b[0m\u001b[1;32m   2696\u001b[0m         return self._reindex_with_indexers({0: [new_index, indexer]},\n\u001b[1;32m   2697\u001b[0m                                            \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   2337\u001b[0m                     indexer = self.get_indexer(target, method=method,\n\u001b[1;32m   2338\u001b[0m                                                \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2339\u001b[0;31m                                                tolerance=tolerance)\n\u001b[0m\u001b[1;32m   2340\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlimit\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2077\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             return this.get_indexer(target, method=method, limit=limit,\n\u001b[0;32m-> 2079\u001b[0;31m                                     tolerance=tolerance)\n\u001b[0m\u001b[1;32m   2080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pad'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'backfill'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2086\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_fill_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2087\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nearest'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2088\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_nearest_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_fill_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2107\u001b[0m             method = (self._engine.get_pad_indexer if method == 'pad' else\n\u001b[1;32m   2108\u001b[0m                       self._engine.get_backfill_indexer)\n\u001b[0;32m-> 2109\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m             indexer = self._get_fill_indexer_searchsorted(target, method,\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.ObjectEngine.get_pad_indexer (pandas\\index.c:9736)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\generated.pyx\u001b[0m in \u001b[0;36mpandas.algos.pad_object (pandas\\algos.c:67769)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unorderable types: str() < int()"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.DataFrame([1,2,3,4,5])\n",
    "print(a)\n",
    "b = a.reindex(index=['a','b','c','d','e','f'],method = 'ffill')\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2013-01-01  2.311522 -0.102904  0.747265  1.605836\n",
      "2013-01-02 -0.467446 -0.102112 -1.505544 -0.557765\n",
      "2013-01-03  0.789258 -0.267605 -0.589914 -0.404398\n",
      "2013-01-04 -1.265446  0.687861 -2.483187  0.673944\n",
      "2013-01-05 -0.918934  1.229446 -0.721240  0.845361\n",
      "2013-01-06 -1.394584 -0.971468  1.091766 -0.092729\n",
      "                   A         B         C         D\n",
      "2013-01-01  2.311522 -0.102904  0.747265  1.605836\n",
      "2013-01-02 -0.467446 -0.102112 -1.505544 -0.557765\n",
      "2013-01-03  0.789258 -0.267605 -0.589914 -0.404398\n",
      "2013-01-04 -1.265446  0.687861 -2.483187  0.673944\n",
      "2013-01-05 -0.918934  1.229446 -0.721240  0.845361\n",
      "2013-01-06 -1.394584 -0.971468  1.091766 -0.092729\n",
      "2013-01-07 -1.394584 -0.971468  1.091766 -0.092729\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dates = pd.date_range('20130101', periods=6)\n",
    "date7 = pd.date_range('20130101', periods=7)\n",
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "print(df)\n",
    "print(df.reindex(index=date7,method='ffill'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method reindex in module pandas.core.frame:\n",
      "\n",
      "reindex(index=None, columns=None, **kwargs) method of pandas.core.frame.DataFrame instance\n",
      "    Conform DataFrame to new index with optional filling logic, placing\n",
      "    NA/NaN in locations having no value in the previous index. A new object\n",
      "    is produced unless the new index is equivalent to the current one and\n",
      "    copy=False\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    index, columns : array-like, optional (can be specified in order, or as\n",
      "        keywords)\n",
      "        New labels / index to conform to. Preferably an Index object to\n",
      "        avoid duplicating data\n",
      "    method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      "        method to use for filling holes in reindexed DataFrame.\n",
      "        Please note: this is only  applicable to DataFrames/Series with a\n",
      "        monotonically increasing/decreasing index.\n",
      "    \n",
      "        * default: don't fill gaps\n",
      "        * pad / ffill: propagate last valid observation forward to next\n",
      "          valid\n",
      "        * backfill / bfill: use next valid observation to fill gap\n",
      "        * nearest: use nearest valid observations to fill gap\n",
      "    \n",
      "    copy : boolean, default True\n",
      "        Return a new object, even if the passed indexes are the same\n",
      "    level : int or name\n",
      "        Broadcast across a level, matching Index values on the\n",
      "        passed MultiIndex level\n",
      "    fill_value : scalar, default np.NaN\n",
      "        Value to use for missing values. Defaults to NaN, but can be any\n",
      "        \"compatible\" value\n",
      "    limit : int, default None\n",
      "        Maximum number of consecutive elements to forward or backward fill\n",
      "    tolerance : optional\n",
      "        Maximum distance between original and new labels for inexact\n",
      "        matches. The values of the index at the matching locations most\n",
      "        satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      "    \n",
      "        .. versionadded:: 0.17.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    Create a dataframe with some fictional data.\n",
      "    \n",
      "    >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      "    >>> df = pd.DataFrame({\n",
      "    ...      'http_status': [200,200,404,404,301],\n",
      "    ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      "    ...       index=index)\n",
      "    >>> df\n",
      "                http_status  response_time\n",
      "    Firefox            200           0.04\n",
      "    Chrome             200           0.02\n",
      "    Safari             404           0.07\n",
      "    IE10               404           0.08\n",
      "    Konqueror          301           1.00\n",
      "    \n",
      "    Create a new index and reindex the dataframe. By default\n",
      "    values in the new index that do not have corresponding\n",
      "    records in the dataframe are assigned ``NaN``.\n",
      "    \n",
      "    >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      "    ...             'Chrome']\n",
      "    >>> df.reindex(new_index)\n",
      "                   http_status  response_time\n",
      "    Safari                 404           0.07\n",
      "    Iceweasel              NaN            NaN\n",
      "    Comodo Dragon          NaN            NaN\n",
      "    IE10                   404           0.08\n",
      "    Chrome                 200           0.02\n",
      "    \n",
      "    We can fill in the missing values by passing a value to\n",
      "    the keyword ``fill_value``. Because the index is not monotonically\n",
      "    increasing or decreasing, we cannot use arguments to the keyword\n",
      "    ``method`` to fill the ``NaN`` values.\n",
      "    \n",
      "    >>> df.reindex(new_index, fill_value=0)\n",
      "                   http_status  response_time\n",
      "    Safari                 404           0.07\n",
      "    Iceweasel                0           0.00\n",
      "    Comodo Dragon            0           0.00\n",
      "    IE10                   404           0.08\n",
      "    Chrome                 200           0.02\n",
      "    \n",
      "    >>> df.reindex(new_index, fill_value='missing')\n",
      "                  http_status response_time\n",
      "    Safari                404          0.07\n",
      "    Iceweasel         missing       missing\n",
      "    Comodo Dragon     missing       missing\n",
      "    IE10                  404          0.08\n",
      "    Chrome                200          0.02\n",
      "    \n",
      "    To further illustrate the filling functionality in\n",
      "    ``reindex``, we will create a dataframe with a\n",
      "    monotonically increasing index (for example, a sequence\n",
      "    of dates).\n",
      "    \n",
      "    >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      "    >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      "    ...                    index=date_index)\n",
      "    >>> df2\n",
      "                prices\n",
      "    2010-01-01     100\n",
      "    2010-01-02     101\n",
      "    2010-01-03     NaN\n",
      "    2010-01-04     100\n",
      "    2010-01-05      89\n",
      "    2010-01-06      88\n",
      "    \n",
      "    Suppose we decide to expand the dataframe to cover a wider\n",
      "    date range.\n",
      "    \n",
      "    >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      "    >>> df2.reindex(date_index2)\n",
      "                prices\n",
      "    2009-12-29     NaN\n",
      "    2009-12-30     NaN\n",
      "    2009-12-31     NaN\n",
      "    2010-01-01     100\n",
      "    2010-01-02     101\n",
      "    2010-01-03     NaN\n",
      "    2010-01-04     100\n",
      "    2010-01-05      89\n",
      "    2010-01-06      88\n",
      "    2010-01-07     NaN\n",
      "    \n",
      "    The index entries that did not have a value in the original data frame\n",
      "    (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      "    If desired, we can fill in the missing values using one of several\n",
      "    options.\n",
      "    \n",
      "    For example, to backpropagate the last valid value to fill the ``NaN``\n",
      "    values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      "    \n",
      "    >>> df2.reindex(date_index2, method='bfill')\n",
      "                prices\n",
      "    2009-12-29     100\n",
      "    2009-12-30     100\n",
      "    2009-12-31     100\n",
      "    2010-01-01     100\n",
      "    2010-01-02     101\n",
      "    2010-01-03     NaN\n",
      "    2010-01-04     100\n",
      "    2010-01-05      89\n",
      "    2010-01-06      88\n",
      "    2010-01-07     NaN\n",
      "    \n",
      "    Please note that the ``NaN`` value present in the original dataframe\n",
      "    (at index value 2010-01-03) will not be filled by any of the\n",
      "    value propagation schemes. This is because filling while reindexing\n",
      "    does not look at dataframe values, but only compares the original and\n",
      "    desired indexes. If you do want to fill in the ``NaN`` values present\n",
      "    in the original dataframe, use the ``fillna()`` method.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    reindexed : DataFrame\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.reindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: ser1, dtype: int64\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: ser1, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1,2,3,4], name=\"ser1\")\n",
    "p = pd.DataFrame(s)\n",
    "print(p.values)\n",
    "print(type(p.values))\n",
    "print(type(p))\n",
    "print(s)\n",
    "print(p.ser1)\n",
    "print(type(p.ser1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "[1 2 3 4]\n",
      "<class 'numpy.ndarray'>\n",
      "RangeIndex(start=0, stop=4, step=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1,2,3,4], name=\"ser1\")\n",
    "print(type(s))\n",
    "print(s.values)\n",
    "print(type(s.values))\n",
    "print(s.axes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: ser1, dtype: int64\n",
      "0    99\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "Name: ser1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1,2,3,4], name=\"ser1\")\n",
    "\n",
    "print(s)\n",
    "s[0] = 99\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ser1\n",
      "0     1\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "   ser1\n",
      "0    99\n",
      "1     2\n",
      "2     3\n",
      "3     4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1,2,3,4], name=\"ser1\")\n",
    "\n",
    "p = pd.DataFrame(s)\n",
    "\n",
    "print(p)\n",
    "p['ser1'][0] = 99\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: ser1, dtype: int64\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: ser2, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x9d02828>]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFkCAYAAACuFXjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9bb9ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "s = pd.Series([1,2,3,4], name=\"ser1\")\n",
    "\n",
    "s1 = pd.Series([1,2,3,4], name=\"ser2\")\n",
    "print(s)\n",
    "print(s1)\n",
    "plt.plot(s,s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ser1  ser2\n",
      "0     1     1\n",
      "1     2     2\n",
      "2     3     3\n",
      "3     4     4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x9ca2b00>]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFkCAYAAACuFXjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9bc1d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "s = pd.Series([1,2,3,4], name=\"ser1\")\n",
    "\n",
    "s1 = pd.Series([1,2,3,4], name=\"ser2\")\n",
    "\n",
    "p = pd.DataFrame({'ser1':s, \"ser2\":s1})\n",
    "print(p)\n",
    "plt.plot(p[\"ser1\"],p[\"ser2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ser2': array([1, 2, 3, 4], dtype=int64), 'ser1': array([1, 2, 3, 4], dtype=int64)}\n",
      "   ser1  ser2\n",
      "0     1     1\n",
      "1     2     2\n",
      "2     3     3\n",
      "3     4     4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1,2,3,4], name=\"ser1\")\n",
    "\n",
    "s1 = pd.Series([1,2,3,4], name=\"ser2\")\n",
    "\n",
    "d = {s.name : s.values}\n",
    "d.update({s1.name : s1.values})\n",
    "print(d)\n",
    "\n",
    "p = pd.DataFrame(d)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   foreigner  sratio\n",
      "0     603105   69.15\n",
      "1    -405885   68.99\n",
      "2     283715   69.09\n",
      "3     365410   69.02\n",
      "4     302876   68.93\n",
      "5     393534   68.85\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "c1 = pd.Series([603105,-405885,283715,365410, 302876, 393534], name='foreigner')\n",
    "c2= pd.Series([69.15, 68.99, 69.09, 69.02, 68.93, 68.85], name='sratio')\n",
    "\n",
    "data = { ser.name : ser.values for ser in [c1,c2]}\n",
    "\n",
    "d = pd.DataFrame(data)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    603105\n",
      "1   -405885\n",
      "2    283715\n",
      "3    365410\n",
      "4    302876\n",
      "5    393534\n",
      "Name: foreigner, dtype: int64\n",
      "0    603105\n",
      "2    283715\n",
      "3    365410\n",
      "4    302876\n",
      "5    393534\n",
      "Name: foreigner, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "c1 = pd.Series([603105,-405885,283715,365410, 302876, 393534], name='foreigner')\n",
    "print(c1)\n",
    "\n",
    "del c1[1]\n",
    "\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
